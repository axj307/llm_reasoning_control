{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Control Model Training Notebook\n",
    "\n",
    "This notebook trains a universal model that can control multiple systems. It follows the progressive training approach:\n",
    "1. Train on Double Integrator first\n",
    "2. Extend the model to Van der Pol oscillator\n",
    "3. Create a universal model that controls both systems\n",
    "\n",
    "**Sections:**\n",
    "1. Setup & Data Loading\n",
    "2. Double Integrator Training\n",
    "3. Van der Pol Extension Training\n",
    "4. Universal Model Training\n",
    "5. Cross-System Evaluation\n",
    "6. Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from config import ALL_CONFIG, AVAILABLE_SYSTEMS\n",
    "from core.model_manager import UniversalModelManager\n",
    "from core.data_pipeline import UniversalDataGenerator\n",
    "from training.sft_training import train_sft_model, setup_universal_chat_template, save_sft_model\n",
    "from training.grpo_training import train_grpo_model, save_grpo_model\n",
    "from evaluation.inference import run_batch_inference\n",
    "from evaluation.metrics import compute_batch_metrics\n",
    "from evaluation.visualization import plot_comparison, plot_metrics_comparison\n",
    "from environments import get_system\n",
    "from data_utils import load_train_eval_datasets, list_available_datasets\n",
    "from gpu_utils import auto_gpu_config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ All modules loaded successfully!\")\n",
    "print(f\"Available systems: {AVAILABLE_SYSTEMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SYSTEMS = [\"double_integrator\", \"van_der_pol\"]\n",
    "DATASET_NAMES = [\"di\", \"vdp\"]  # Simple clean names\n",
    "LORA_RANK = 8\n",
    "MAX_SEQ_LENGTH = 1024\n",
    "\n",
    "print(f\"üéØ Training systems: {', '.join(SYSTEMS)}\")\n",
    "print(f\"üìä Datasets: {', '.join(DATASET_NAMES)}\")\n",
    "print(f\"üîß LoRA rank: {LORA_RANK}\")\n",
    "print(f\"üìè Max sequence length: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available datasets\n",
    "print(\"üìÇ Available datasets:\")\n",
    "datasets = list_available_datasets(\"../datasets\")\n",
    "if datasets:\n",
    "    for dataset in datasets:\n",
    "        print(f\"   ‚Ä¢ {dataset}\")\n",
    "else:\n",
    "    print(\"   No datasets found\")\n",
    "    \n",
    "# Check if we have both required datasets\n",
    "missing_datasets = []\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    if dataset_name not in datasets:\n",
    "        missing_datasets.append(dataset_name)\n",
    "\n",
    "if missing_datasets:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing datasets: {', '.join(missing_datasets)}\")\n",
    "    print(\"üí° Run the individual training notebooks first to generate datasets\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required datasets are available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "all_datasets = {}\n",
    "\n",
    "for system_name, dataset_name in zip(SYSTEMS, DATASET_NAMES):\n",
    "    try:\n",
    "        train_data, eval_data, dataset_info = load_train_eval_datasets(\n",
    "            dataset_name, \"../datasets\", system_name\n",
    "        )\n",
    "        all_datasets[system_name] = {\n",
    "            'train': train_data,\n",
    "            'eval': eval_data,\n",
    "            'info': dataset_info\n",
    "        }\n",
    "        print(f\"‚úÖ {system_name}: {len(train_data)} train + {len(eval_data)} eval samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {system_name} dataset: {e}\")\n",
    "\n",
    "if len(all_datasets) == len(SYSTEMS):\n",
    "    print(\"\\nüéâ All datasets loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Some datasets failed to load. Please check the individual training notebooks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU and model manager\n",
    "print(\"üéØ Setting up GPU and model...\")\n",
    "\n",
    "# Auto-select best GPU\n",
    "gpu_config = auto_gpu_config()\n",
    "print(f\"üñ•Ô∏è  Selected GPU: {gpu_config['gpu_id']}\")\n",
    "\n",
    "# Create model manager\n",
    "manager = UniversalModelManager(ALL_CONFIG[\"model\"][\"base_model_name\"])\n",
    "\n",
    "# Setup model\n",
    "model, tokenizer = manager.setup_model(\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    lora_rank=LORA_RANK,\n",
    "    gpu_id=gpu_config['gpu_id'],\n",
    "    auto_select_gpu=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Progressive Training: Double Integrator First\n",
    "\n",
    "Start by training the base model on Double Integrator system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Train on Double Integrator\n",
    "TRAIN_DI_PHASE = True  # Set to True to train DI phase\n",
    "\n",
    "if TRAIN_DI_PHASE and 'double_integrator' in all_datasets:\n",
    "    print(\"üöÄ Phase 1: Training on Double Integrator...\")\n",
    "    \n",
    "    # Setup chat template for DI only first\n",
    "    setup_universal_chat_template(\n",
    "        manager, [\"double_integrator\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    # Get DI data\n",
    "    di_train = all_datasets['double_integrator']['train']\n",
    "    di_eval = all_datasets['double_integrator']['eval']\n",
    "    \n",
    "    # === DI SFT Phase ===\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìö DOUBLE INTEGRATOR SFT TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sft_config = ALL_CONFIG[\"sft\"].copy()\n",
    "    sft_config[\"output_dir\"] = \"../temp_training/universal/di_sft\"\n",
    "    \n",
    "    di_sft_result = train_sft_model(\n",
    "        manager, di_train, di_eval, sft_config\n",
    "    )\n",
    "    \n",
    "    di_sft_path = save_sft_model(\n",
    "        manager, [\"double_integrator\"], di_sft_result[\"metrics\"], \"di_base_sft\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ DI SFT model saved to: {di_sft_path}\")\n",
    "    \n",
    "    # === DI GRPO Phase ===\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéÆ DOUBLE INTEGRATOR GRPO TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    grpo_config = ALL_CONFIG[\"grpo\"].copy()\n",
    "    grpo_config[\"output_dir\"] = \"../temp_training/universal/di_grpo\"\n",
    "    \n",
    "    di_grpo_result = train_grpo_model(\n",
    "        manager, di_train, di_eval, grpo_config,\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    di_grpo_path = save_grpo_model(\n",
    "        manager, [\"double_integrator\"], di_grpo_result[\"metrics\"], \"di_base_grpo\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ DI GRPO model saved to: {di_grpo_path}\")\n",
    "    print(\"\\nüéâ Phase 1 Complete: Double Integrator model ready!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping DI phase (set TRAIN_DI_PHASE=True and ensure DI dataset is loaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Progressive Training: Extend to Van der Pol\n",
    "\n",
    "Now extend the trained DI model to handle Van der Pol oscillator as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Extend to Van der Pol\n",
    "TRAIN_VDP_EXTENSION = True  # Set to True to train VDP extension\n",
    "\n",
    "if TRAIN_VDP_EXTENSION and len(all_datasets) == 2:\n",
    "    print(\"üöÄ Phase 2: Extending to Van der Pol...\")\n",
    "    \n",
    "    # Setup universal chat template for both systems\n",
    "    setup_universal_chat_template(\n",
    "        manager, SYSTEMS,\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    # Combine datasets for universal training\n",
    "    print(\"üîÑ Combining datasets...\")\n",
    "    \n",
    "    # Mix training data from both systems\n",
    "    combined_train = []\n",
    "    combined_eval = []\n",
    "    \n",
    "    for system_name in SYSTEMS:\n",
    "        combined_train.extend(all_datasets[system_name]['train'])\n",
    "        combined_eval.extend(all_datasets[system_name]['eval'])\n",
    "    \n",
    "    # Shuffle the combined data\n",
    "    import random\n",
    "    random.shuffle(combined_train)\n",
    "    random.shuffle(combined_eval)\n",
    "    \n",
    "    print(f\"üìä Combined training data: {len(combined_train)} samples\")\n",
    "    print(f\"üìä Combined eval data: {len(combined_eval)} samples\")\n",
    "    \n",
    "    # === Universal SFT Phase ===\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìö UNIVERSAL SFT TRAINING (DI + VDP)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    universal_sft_config = ALL_CONFIG[\"sft\"].copy()\n",
    "    universal_sft_config[\"output_dir\"] = \"../temp_training/universal/combined_sft\"\n",
    "    universal_sft_config[\"num_train_epochs\"] = 2  # Less epochs since we're extending\n",
    "    \n",
    "    universal_sft_result = train_sft_model(\n",
    "        manager, combined_train, combined_eval, universal_sft_config\n",
    "    )\n",
    "    \n",
    "    universal_sft_path = save_sft_model(\n",
    "        manager, SYSTEMS, universal_sft_result[\"metrics\"], \"universal_sft\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Universal SFT model saved to: {universal_sft_path}\")\n",
    "    \n",
    "    # === Universal GRPO Phase ===\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéÆ UNIVERSAL GRPO TRAINING (DI + VDP)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    universal_grpo_config = ALL_CONFIG[\"grpo\"].copy()\n",
    "    universal_grpo_config[\"output_dir\"] = \"../temp_training/universal/combined_grpo\"\n",
    "    universal_grpo_config[\"max_steps\"] = 150  # More steps for universal training\n",
    "    \n",
    "    universal_grpo_result = train_grpo_model(\n",
    "        manager, combined_train, combined_eval, universal_grpo_config,\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    universal_grpo_path = save_grpo_model(\n",
    "        manager, SYSTEMS, universal_grpo_result[\"metrics\"], \"universal_grpo\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Universal GRPO model saved to: {universal_grpo_path}\")\n",
    "    print(\"\\nüéâ Phase 2 Complete: Universal model ready!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping VDP extension (set TRAIN_VDP_EXTENSION=True and ensure both datasets are loaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Universal Model Evaluation\n",
    "\n",
    "Test the universal model on both systems to verify it can control both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal Model Evaluation\n",
    "RUN_UNIVERSAL_EVALUATION = True  # Set to True to run evaluation\n",
    "\n",
    "if RUN_UNIVERSAL_EVALUATION:\n",
    "    print(\"üìä Starting Universal Model Evaluation...\")\n",
    "    \n",
    "    # Load universal model for evaluation\n",
    "    eval_manager = UniversalModelManager()\n",
    "    \n",
    "    try:\n",
    "        universal_model, universal_tokenizer, universal_lora, universal_metadata = eval_manager.load_universal_model()\n",
    "        \n",
    "        print(f\"‚úÖ Loaded universal model trained on: {universal_metadata.get('trained_systems', SYSTEMS)}\")\n",
    "        \n",
    "        # Evaluation results storage\n",
    "        evaluation_results = {}\n",
    "        \n",
    "        # Test on each system\n",
    "        for system_name in SYSTEMS:\n",
    "            print(f\"\\nüîç Testing universal model on {system_name.upper()}...\")\n",
    "            \n",
    "            # Generate test cases\n",
    "            system = get_system(system_name)()\n",
    "            test_cases = []\n",
    "            for _ in range(10):  # 10 test cases per system\n",
    "                initial_state = system.generate_random_initial_state()\n",
    "                test_cases.append(tuple(initial_state))\n",
    "            \n",
    "            # Run inference\n",
    "            from vllm import SamplingParams\n",
    "            sampling_params = SamplingParams(\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                max_tokens=1024\n",
    "            )\n",
    "            \n",
    "            results = run_batch_inference(\n",
    "                universal_model, universal_tokenizer, system_name, test_cases,\n",
    "                lora_request=universal_lora,\n",
    "                sampling_params=sampling_params\n",
    "            )\n",
    "            \n",
    "            # Compute metrics\n",
    "            metrics = compute_batch_metrics(results)\n",
    "            evaluation_results[system_name] = {\n",
    "                'results': results,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            \n",
    "            print(f\"   Success rate: {metrics['success_rate']:.2%}\")\n",
    "            print(f\"   Mean performance: {metrics['mean_performance_score']:.4f}\")\n",
    "            \n",
    "        print(\"\\n‚úÖ Universal model evaluation complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Universal model evaluation failed: {e}\")\n",
    "        print(\"üí° Make sure the universal training phase completed successfully\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping universal evaluation (set RUN_UNIVERSAL_EVALUATION=True to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative Analysis\n",
    "if RUN_UNIVERSAL_EVALUATION and 'evaluation_results' in locals():\n",
    "    print(\"üìà Generating comparative analysis...\")\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÜ UNIVERSAL MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for system_name in SYSTEMS:\n",
    "        if system_name in evaluation_results:\n",
    "            metrics = evaluation_results[system_name]['metrics']\n",
    "            print(f\"\\nüìä {system_name.upper().replace('_', ' ')}:\")\n",
    "            print(f\"   ‚úì Success Rate: {metrics['success_rate']:.1%}\")\n",
    "            print(f\"   ‚ö° Mean Performance: {metrics['mean_performance_score']:.4f}\")\n",
    "            if 'mean_final_error' in metrics:\n",
    "                print(f\"   üéØ Mean Final Error: {metrics['mean_final_error']:.6f}\")\n",
    "    \n",
    "    # Visualization for each system\n",
    "    for system_name in SYSTEMS:\n",
    "        if system_name in evaluation_results:\n",
    "            print(f\"\\nüìà Generating plots for {system_name}...\")\n",
    "            \n",
    "            results = evaluation_results[system_name]['results']\n",
    "            \n",
    "            # Plot trajectory comparison\n",
    "            fig1 = plot_comparison(results)\n",
    "            if fig1:\n",
    "                plt.figure(fig1.number)\n",
    "                plt.suptitle(f\"Universal Model on {system_name.replace('_', ' ').title()}\", fontsize=16)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            # Plot metrics comparison\n",
    "            fig2 = plot_metrics_comparison(results)\n",
    "            if fig2:\n",
    "                plt.figure(fig2.number)\n",
    "                plt.suptitle(f\"{system_name.replace('_', ' ').title()} Performance Metrics\", fontsize=16)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Comparative analysis complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  No evaluation results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Loading for Further Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models for interactive use\n",
    "print(\"üîß Loading models for interactive use...\")\n",
    "\n",
    "# Load universal model\n",
    "try:\n",
    "    final_manager = UniversalModelManager()\n",
    "    universal_model, universal_tokenizer, universal_lora, universal_metadata = final_manager.load_universal_model()\n",
    "    \n",
    "    print(\"‚úÖ Universal model loaded and ready for use!\")\n",
    "    print(f\"   üìç Trained on systems: {universal_metadata.get('trained_systems', SYSTEMS)}\")\n",
    "    print(f\"   üìÖ Training date: {universal_metadata.get('timestamp', 'Unknown')}\")\n",
    "    \n",
    "    # Example usage\n",
    "    print(\"\\nüí° Example usage:\")\n",
    "    print(\"```python\")\n",
    "    print(\"# Generate a test case for double integrator\")\n",
    "    print(\"di_system = get_system('double_integrator')()\")\n",
    "    print(\"initial_state = di_system.generate_random_initial_state()\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference\")\n",
    "    print(\"results = run_batch_inference(\")\n",
    "    print(\"    universal_model, universal_tokenizer, 'double_integrator', [initial_state],\")\n",
    "    print(\"    lora_request=universal_lora\")\n",
    "    print(\")\")\n",
    "    print(\"```\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load universal model: {e}\")\n",
    "    print(\"üí° Make sure the training completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook implements the complete universal control model training pipeline:\n",
    "\n",
    "### üéØ **Training Phases:**\n",
    "1. **Phase 1**: Train on Double Integrator (base knowledge)\n",
    "2. **Phase 2**: Extend to Van der Pol (universal capability)\n",
    "\n",
    "### üìä **Key Features:**\n",
    "- **Progressive Learning**: Build from simple to complex systems\n",
    "- **Knowledge Transfer**: Preserve DI knowledge while learning VDP\n",
    "- **Universal Control**: Single model controls multiple systems\n",
    "- **Cross-System Evaluation**: Test performance on both systems\n",
    "\n",
    "### üèÜ **Model Outputs:**\n",
    "- **DI Specialist**: `models/single_system/double_integrator/grpo/latest/`\n",
    "- **Universal Model**: `models/universal/grpo/latest/`\n",
    "\n",
    "### üî¨ **Research Benefits:**\n",
    "- Compare specialist vs universal performance\n",
    "- Study knowledge transfer in control tasks\n",
    "- Evaluate generalization across system types\n",
    "- Test scalability to additional systems\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "- Add more control systems (pendulum, cartpole, etc.)\n",
    "- Experiment with different training orders\n",
    "- Test few-shot adaptation to new systems\n",
    "- Implement continual learning strategies\n",
    "\n",
    "The universal model is now ready for control research! üéõÔ∏èü§ñ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}