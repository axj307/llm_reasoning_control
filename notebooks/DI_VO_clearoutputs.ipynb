{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Hb6Dvoi2VM"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I4w4OUE9lvo"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furZbyFy9lvq"
      },
      "source": [
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt29NJfP9lvs"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkH_y8UC9lvv"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN75nmdx9lvw"
      },
      "source": [
        "Goal: To convert `Qwen3-4B-Base` into a reasoning model via GRPO by using OpenR1's Math dataset.\n",
        "\n",
        "We first pre fine-tune the model to make GRPO skip trying to match formatting - this speeds GRPO up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import os\n",
        "# import random\n",
        "\n",
        "# num_gpus = torch.cuda.device_count()\n",
        "# if num_gpus > 0:\n",
        "#     chosen_gpu = random.randint(0, num_gpus - 1)\n",
        "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(chosen_gpu)\n",
        "#     print(f\"Randomly selected GPU: {chosen_gpu}\")\n",
        "# else:\n",
        "#     print(\"No GPUs available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750,
          "referenced_widgets": [
            "2f8779bce6e249c2846639cf3431cd74",
            "df3ea2ea5de243fa8b5bdaab82f7b7c3",
            "36323e9f8ce040c2b9ba0d67f2d88d1a",
            "23111afc4a914829a3d24314ca66f33d",
            "edacc2c8ff9e4eaf886e5b49e21b7e11",
            "e2e1e56e67b240f1802ce888c62c9860",
            "dab2cfcb9e53486582d98dd35c56654a",
            "326713cc0b7c478291652c9324127149",
            "802bf28a6a144a049e9b3f3af234f88c",
            "38cdb5f4454d4cb8af8a055c536912e3",
            "7e145207293e420f8a5be01a85e5861b",
            "58f2c1ecbeeb4b53af6aa3264008e6dc",
            "207997f1fc1e4ab68a0de0b880bfae55",
            "5fb90177a4fa480c8c80474be786cbae",
            "051022abbc21456f89ac56364f827a73",
            "db1133419f184e459153347ff2653c17",
            "ec663b7c3d774d3cb976e6d1fa30a999",
            "f22b1d60ae234506b37cb11aa5c5de51",
            "8a5e3fe437024acc89e4caf71447a558",
            "d29a6452c0cd49b3932206e8aa0b4c1c",
            "5218777759ce48f79834aefc8e9a9320",
            "a3d222daa599414b9d31a4bc9fed9c2c"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "70accc89-9ee2-439b-e456-d536e22ccfb7"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Can increase for longer reasoning traces\n",
        "lora_rank = 16 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-4B-Base\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.7, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
        "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
        "    random_state = 3407,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9DuiVRLhMco"
      },
      "source": [
        "### GRPO chat template\n",
        "Since we're using a base model, we should set a chat template. You can make your own chat template as well!\n",
        "1. DeepSeek uses `<think>` and `</think>`, but this is **not** necessary - you can customize it however you like!\n",
        "2. A `system_prompt` is recommended to at least guide the model's responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6UjowCbT-cFz",
        "outputId": "71bd035e-6cc1-4c1f-979d-e52a700fd913"
      },
      "outputs": [],
      "source": [
        "reasoning_start = \"<REASONING>\"\n",
        "reasoning_end = \"</REASONING>\"\n",
        "solution_start = \"<CONTROLS>\"\n",
        "solution_end = \"</CONTROLS>\"\n",
        "\n",
        "# Time settings - these can be changed by the user before generating a dataset\n",
        "# For example, to aim for 50 steps in 5 seconds:\n",
        "# dt = 0.1\n",
        "# steps = 50\n",
        "# Or for 20 steps in 10 seconds:\n",
        "# dt = 0.5\n",
        "# steps = 20\n",
        "\n",
        "# Default values (can be overridden before running generation)\n",
        "dt = 0.1  # Default time step duration\n",
        "steps = 50 # Default number of steps\n",
        "\n",
        "\n",
        "def get_system_prompt(current_dt, current_steps, system_type=\"double_integrator\"):\n",
        "    total_time = current_dt * current_steps\n",
        "    \n",
        "    if system_type == \"double_integrator\":\n",
        "        return f\"\"\"You are a control systems expert.\n",
        "Given a double integrator system (ẍ = u) with initial position and velocity,\n",
        "generate a sequence of {current_steps} control inputs to reach the origin (0,0) in exactly {total_time:.2f} seconds.\n",
        "Position and velocity must stay within [-1, 1], and control inputs must be within [-3, 3].\n",
        "Explain your approach between {reasoning_start} and {reasoning_end}.\n",
        "Then provide exactly {current_steps} control values as a comma-separated list between {solution_start} and {solution_end}.\"\"\"\n",
        "    \n",
        "    elif system_type == \"van_der_pol\":\n",
        "        return f\"\"\"You are a control systems expert.\n",
        "Given a Van der Pol oscillator system (ẍ - μ(1-x²)ẋ + x = u) with μ=1, initial position and velocity,\n",
        "generate a sequence of {current_steps} control inputs to reach the origin (0,0) in exactly {total_time:.2f} seconds.\n",
        "Position and velocity must stay within [-2, 2], and control inputs must be within [-5, 5].\n",
        "Explain your approach between {reasoning_start} and {reasoning_end}.\n",
        "Then provide exactly {current_steps} control values as a comma-separated list between {solution_start} and {solution_end}.\"\"\"\n",
        "\n",
        "# Initialize global system_prompt with double integrator as default\n",
        "system_prompt = get_system_prompt(dt, steps, \"double_integrator\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGgs0MJkDkYL"
      },
      "source": [
        "We create a simple chat template below. Notice `add_generation_prompt` includes prepending `<start_working_out>` to guide the model to start its reasoning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3fF9gMujY02"
      },
      "outputs": [],
      "source": [
        "chat_template = \\\n",
        "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
        "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages[1:] %}\"\\\n",
        "    \"{% else %}\"\\\n",
        "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages %}\"\\\n",
        "    \"{% endif %}\"\\\n",
        "    \"{% for message in loop_messages %}\"\\\n",
        "        \"{% if message['role'] == 'user' %}\"\\\n",
        "            \"{{ message['content'] }}\"\\\n",
        "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
        "            \"{{ message['content'] + eos_token }}\"\\\n",
        "        \"{% endif %}\"\\\n",
        "    \"{% endfor %}\"\\\n",
        "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
        "    \"{% endif %}\"\n",
        "\n",
        "# Replace with out specific template:\n",
        "chat_template = chat_template\\\n",
        "    .replace(\"'{system_prompt}'\",   f\"'{system_prompt}'\")\\\n",
        "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
        "tokenizer.chat_template = chat_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEcLdymBEHdk"
      },
      "source": [
        "Let's see how our chat template behaves on an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BciEDYSSYFNj",
        "outputId": "0d5669d2-6e42-4c2f-d751-8a72f72b45e4"
      },
      "outputs": [],
      "source": [
        "# tokenizer.apply_chat_template([\n",
        "#     {\"role\" : \"user\", \"content\" : \"What is 1+1?\"},\n",
        "#     {\"role\" : \"assistant\", \"content\" : f\"{reasoning_start}I think it's 2.{reasoning_end}{solution_start}2{solution_end}\"},\n",
        "#     {\"role\" : \"user\", \"content\" : \"What is 2+2?\"},\n",
        "# ], tokenize = False, add_generation_prompt = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mdsuGjxHrjT"
      },
      "source": [
        "### Pre fine-tuning for formatting\n",
        "We now use a subset of NVIDIA's [Open Math Reasoning dataset](https://huggingface.co/datasets/nvidia/OpenMathReasoning) which was filtered to only include high quality DeepSeek R1 traces.\n",
        "\n",
        "We'll only filter ~59 or so examples to first \"prime\" / pre fine-tune the model to understand our custom GRPO formatting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVRFqoSdIEVK"
      },
      "source": [
        "We have to format the dataset to follow our GRPO style formatting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re # Import re for parsing in evaluate_control_sequence\n",
        "\n",
        "def generate_simple_control_dataset(num_samples=500, target_dt=0.1, target_steps=50):\n",
        "    \"\"\"Generate double integrator control problems with LQR solutions for specific dt and steps.\"\"\"\n",
        "    data = []\n",
        "    total_time_sec = target_dt * target_steps\n",
        "    sample_system_prompt = get_system_prompt(target_dt, target_steps)\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        # Random initial states within bounds\n",
        "        x0 = np.random.uniform(-0.8, 0.8)\n",
        "        v0 = np.random.uniform(-0.8, 0.8)\n",
        "        \n",
        "        # Problem statement\n",
        "        problem = f\"Control a double integrator system with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time_sec:.2f} seconds using {target_steps} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "        \n",
        "        # Solve for optimal control sequence using LQR\n",
        "        control_inputs = solve_double_integrator(x0, v0, target_dt, target_steps)\n",
        "        \n",
        "        # Generate reasoning text with LQR explanation\n",
        "        reasoning = f\"\"\"For the double integrator system starting at position {x0:.2f} and velocity {v0:.2f}, I'll apply Linear Quadratic Regulator (LQR) control to reach the origin optimally in {total_time_sec:.2f} seconds using {target_steps} steps.\n",
        "\n",
        "        The LQR approach provides an optimal feedback control law by minimizing a quadratic cost function that balances:\n",
        "        1. The error in state (position and velocity)\n",
        "        2. The control effort used\n",
        "\n",
        "        For a double integrator with dynamics:\n",
        "        - ẋ = v\n",
        "        - v̇ = u\n",
        "\n",
        "        The discrete-time state-space representation is:\n",
        "        - x(k+1) = Ax(k) + Bu(k)\n",
        "\n",
        "        Where:\n",
        "        - A = [[1, Δt], [0, 1]]\n",
        "        - B = [[0.5(Δt)², Δt]]\n",
        "        - Δt = {target_dt:.2f} seconds\n",
        "\n",
        "        Computing the optimal gain matrix K through the Riccati equation gives a feedback law u = -Kx.\n",
        "        This produces a smooth control sequence that brings the system to the origin while respecting constraints.\n",
        "\n",
        "        The resulting {target_steps} control inputs applied over {total_time_sec:.2f} seconds will optimally control the system to the target state.\"\"\"\n",
        "        # Format reasoning text        \n",
        "        # Format control values\n",
        "        control_str = \", \".join([f\"{u:.3f}\" for u in control_inputs])\n",
        "        \n",
        "        # Create output\n",
        "        complete_output = f\"{reasoning_start}{reasoning}{reasoning_end}{solution_start}{control_str}{solution_end}\"\n",
        "        \n",
        "        # Add to dataset\n",
        "        data.append({\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": sample_system_prompt}, # Use sample-specific system prompt\n",
        "                {\"role\": \"user\", \"content\": problem}\n",
        "            ],\n",
        "            \"answer\": control_str,\n",
        "            \"Messages\": [\n",
        "                {\"role\": \"system\", \"content\": sample_system_prompt}, # Use sample-specific system prompt\n",
        "                {\"role\": \"user\", \"content\": problem},\n",
        "                {\"role\": \"assistant\", \"content\": complete_output}\n",
        "            ]\n",
        "        })\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def solve_double_integrator(x0, v0, dt, steps):\n",
        "    \"\"\"\n",
        "    Compute LQR optimal control sequence for the double integrator.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import scipy.linalg as la\n",
        "    \n",
        "    # System dynamics for double integrator in discrete time\n",
        "    A = np.array([[1, dt], \n",
        "                 [0, 1]])\n",
        "    \n",
        "    B = np.array([[0.5*dt**2], \n",
        "                 [dt]])\n",
        "    \n",
        "    # Cost matrices\n",
        "    Q = np.diag([10.0, 10.0])  # State cost: position error more important than velocity\n",
        "    R = np.array([[0.1]])   # Control cost (small to allow sufficient control)\n",
        "    \n",
        "    # Solve discrete time algebraic Riccati equation\n",
        "    P = la.solve_discrete_are(A, B, Q, R)\n",
        "    \n",
        "    # Compute optimal feedback gain\n",
        "    K = np.linalg.inv(R + B.T @ P @ B) @ B.T @ P @ A\n",
        "    \n",
        "    # Initial state\n",
        "    x = np.array([[x0], [v0]])\n",
        "    \n",
        "    # Simulate the closed loop system and get control sequence\n",
        "    controls = []\n",
        "    states = [x.copy()]\n",
        "    \n",
        "    for i in range(steps):\n",
        "        # Compute optimal control: u = -K*x\n",
        "        u = -K @ x\n",
        "        \n",
        "        # Clamp control within bounds\n",
        "        u_clamped = max(-3.0, min(3.0, float(u[0])))\n",
        "        \n",
        "        # Apply control to system\n",
        "        x = A @ x + B * u_clamped\n",
        "        \n",
        "        # Clamp states if needed (though LQR should respect constraints if tuned well)\n",
        "        x[0,0] = max(-1.0, min(1.0, x[0,0]))  # Position\n",
        "        x[1,0] = max(-1.0, min(1.0, x[1,0]))  # Velocity\n",
        "        \n",
        "        # Save control and state\n",
        "        controls.append(u_clamped)\n",
        "        states.append(x.copy())\n",
        "    \n",
        "    return controls\n",
        "\n",
        "\n",
        "def solve_van_der_pol(x0, v0, mu=1.0, dt=0.1, steps=50):\n",
        "    \"\"\"\n",
        "    Compute control sequence for the Van der Pol oscillator using numerical optimization.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from scipy.integrate import solve_ivp\n",
        "    import scipy.optimize as opt\n",
        "    \n",
        "    # Define Van der Pol dynamics with control\n",
        "    def van_der_pol_dynamics(t, state, u):\n",
        "        x, v = state\n",
        "        dxdt = v\n",
        "        dvdt = mu * (1 - x**2) * v - x + u\n",
        "        return [dxdt, dvdt]\n",
        "    \n",
        "    # Define cost function for optimization\n",
        "    def cost_function(u_sequence):\n",
        "        # Initialize state\n",
        "        state = [x0, v0]\n",
        "        states = [state.copy()]\n",
        "        total_cost = 0\n",
        "        \n",
        "        # Simulate forward with these controls\n",
        "        for i, u in enumerate(u_sequence):\n",
        "            # Bound control\n",
        "            u = max(-5.0, min(5.0, u))\n",
        "            \n",
        "            # Simulate one step\n",
        "            sol = solve_ivp(\n",
        "                lambda t, y: van_der_pol_dynamics(t, y, u), \n",
        "                [0, dt], state, method='RK45', t_eval=[dt]\n",
        "            )\n",
        "            state = sol.y[:, -1].tolist()\n",
        "            states.append(state.copy())\n",
        "            \n",
        "            # Compute step cost (quadratic state and control costs)\n",
        "            state_cost = 10.0 * state[0]**2 + 5.0 * state[1]**2\n",
        "            control_cost = 0.1 * u**2\n",
        "            \n",
        "            # Higher weight for final states\n",
        "            time_weight = 1.0 if i < steps-5 else 5.0\n",
        "            step_cost = time_weight * (state_cost + control_cost)\n",
        "            total_cost += step_cost\n",
        "        \n",
        "        # Extra penalty for final state not being at origin\n",
        "        final_x, final_v = states[-1]\n",
        "        final_cost = 50.0 * (final_x**2 + final_v**2)\n",
        "        \n",
        "        return total_cost + final_cost\n",
        "    \n",
        "    # Optimize control sequence\n",
        "    initial_guess = np.zeros(steps)\n",
        "    bounds = [(-5, 5)] * steps\n",
        "    \n",
        "    result = opt.minimize(\n",
        "        cost_function, \n",
        "        initial_guess, \n",
        "        method='SLSQP', \n",
        "        bounds=bounds,\n",
        "        options={'maxiter': 500}\n",
        "    )\n",
        "    \n",
        "    # Return optimal control sequence\n",
        "    controls = np.clip(result.x, -5.0, 5.0).tolist()\n",
        "    return controls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def visualize_lqr_solution(x0, v0, dt, steps):\n",
        "#     \"\"\"Visualize an LQR solution for a specific initial state.\"\"\"\n",
        "#     import matplotlib.pyplot as plt\n",
        "    \n",
        "#     controls = solve_double_integrator(x0, v0, dt, steps)\n",
        "    \n",
        "#     # Simulate trajectory\n",
        "#     x, v = x0, v0\n",
        "#     positions = [x]\n",
        "#     velocities = [v]\n",
        "#     times = [0]\n",
        "    \n",
        "#     for i, u in enumerate(controls):\n",
        "#         v = v + u * dt\n",
        "#         x = x + v * dt\n",
        "#         positions.append(x)\n",
        "#         velocities.append(v)\n",
        "#         times.append((i+1) * dt)\n",
        "    \n",
        "#     # Plot results\n",
        "#     plt.figure(figsize=(12, 8))\n",
        "    \n",
        "#     plt.subplot(3, 1, 1)\n",
        "#     plt.plot(times, positions, 'b-o')\n",
        "#     plt.axhline(y=0, color='r', linestyle='--')\n",
        "#     plt.grid(True)\n",
        "#     plt.ylabel('Position')\n",
        "#     plt.title('LQR Control Solution')\n",
        "    \n",
        "#     plt.subplot(3, 1, 2)\n",
        "#     plt.plot(times, velocities, 'g-o')\n",
        "#     plt.axhline(y=0, color='r', linestyle='--')\n",
        "#     plt.grid(True)\n",
        "#     plt.ylabel('Velocity')\n",
        "    \n",
        "#     plt.subplot(3, 1, 3)\n",
        "#     plt.step(times[:-1], controls, 'r-o', where='post')\n",
        "#     plt.grid(True)\n",
        "#     plt.xlabel('Time (s)')\n",
        "#     plt.ylabel('Control Input')\n",
        "    \n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "    \n",
        "#     return positions[-1], velocities[-1]\n",
        "\n",
        "# # Test with a few initial states to verify LQR behavior\n",
        "# visualize_lqr_solution(0.5, -0.3, dt, steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_combined_control_dataset(num_samples_per_system=250, target_dt=0.1, target_steps=50):\n",
        "    \"\"\"\n",
        "    Generate training data for both double integrator and Van der Pol oscillator systems.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    total_time_sec = target_dt * target_steps\n",
        "    \n",
        "    # Generate double integrator data\n",
        "    for i in range(num_samples_per_system):\n",
        "        # Random initial states within bounds\n",
        "        x0 = np.random.uniform(-0.8, 0.8)\n",
        "        v0 = np.random.uniform(-0.8, 0.8)\n",
        "        \n",
        "        # System-specific prompt\n",
        "        di_system_prompt = get_system_prompt(target_dt, target_steps, \"double_integrator\")\n",
        "        \n",
        "        # Problem statement\n",
        "        problem = f\"Control a double integrator system with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time_sec:.2f} seconds using {target_steps} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "        \n",
        "        # Solve for optimal control sequence using LQR\n",
        "        control_inputs = solve_double_integrator(x0, v0, target_dt, target_steps)\n",
        "        \n",
        "        # Generate reasoning text with LQR explanation\n",
        "        reasoning = f\"\"\"For the double integrator system starting at position {x0:.2f} and velocity {v0:.2f}, I'll apply Linear Quadratic Regulator (LQR) control to reach the origin optimally in {total_time_sec:.2f} seconds using {target_steps} steps.\n",
        "\n",
        "        The LQR approach provides an optimal feedback control law by minimizing a quadratic cost function that balances:\n",
        "        1. The error in state (position and velocity)\n",
        "        2. The control effort used\n",
        "\n",
        "        For a double integrator with dynamics:\n",
        "        - ẋ = v\n",
        "        - v̇ = u\n",
        "\n",
        "        The discrete-time state-space representation is:\n",
        "        - x(k+1) = Ax(k) + Bu(k)\n",
        "\n",
        "        Where:\n",
        "        - A = [[1, Δt], [0, 1]]\n",
        "        - B = [[0.5(Δt)², Δt]]\n",
        "        - Δt = {target_dt:.2f} seconds\n",
        "\n",
        "        Computing the optimal gain matrix K through the Riccati equation gives a feedback law u = -Kx.\n",
        "        This produces a smooth control sequence that brings the system to the origin while respecting constraints.\n",
        "\n",
        "        The resulting {target_steps} control inputs applied over {total_time_sec:.2f} seconds will optimally control the system to the target state.\"\"\"\n",
        "        \n",
        "        # Format control values\n",
        "        control_str = \", \".join([f\"{u:.3f}\" for u in control_inputs])\n",
        "        \n",
        "        # Create output\n",
        "        complete_output = f\"{reasoning_start}{reasoning}{reasoning_end}{solution_start}{control_str}{solution_end}\"\n",
        "        \n",
        "        # Add to dataset\n",
        "        data.append({\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": di_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": problem}\n",
        "            ],\n",
        "            \"answer\": control_str,\n",
        "            \"Messages\": [\n",
        "                {\"role\": \"system\", \"content\": di_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": problem},\n",
        "                {\"role\": \"assistant\", \"content\": complete_output}\n",
        "            ],\n",
        "            \"system_type\": \"double_integrator\"\n",
        "        })\n",
        "    \n",
        "    # Generate Van der Pol oscillator data\n",
        "    for i in range(num_samples_per_system):\n",
        "        # Random initial states within bounds (slightly wider range for VDP)\n",
        "        x0 = np.random.uniform(-1.5, 1.5)\n",
        "        v0 = np.random.uniform(-1.5, 1.5)\n",
        "        \n",
        "        # System-specific prompt\n",
        "        vdp_system_prompt = get_system_prompt(target_dt, target_steps, \"van_der_pol\")\n",
        "        \n",
        "        # Problem statement\n",
        "        problem = f\"Control a Van der Pol oscillator system (μ=1) with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time_sec:.2f} seconds using {target_steps} steps. Ensure all states remain within [-2,2] and controls within [-5,5].\"\n",
        "        \n",
        "        # Solve for control sequence\n",
        "        control_inputs = solve_van_der_pol(x0, v0, 1.0, target_dt, target_steps)\n",
        "        \n",
        "        # Generate reasoning text\n",
        "        reasoning = f\"\"\"For the Van der Pol oscillator starting at position {x0:.2f} and velocity {v0:.2f}, I'll design a control sequence to reach the origin optimally in {total_time_sec:.2f} seconds using {target_steps} steps.\n",
        "\n",
        "        The Van der Pol oscillator follows the dynamics:\n",
        "        - ẋ = v\n",
        "        - v̇ = μ(1-x²)v - x + u\n",
        "        where μ=1 determines the strength of the nonlinearity.\n",
        "\n",
        "        Unlike the double integrator, this system exhibits self-sustained oscillations and has nonlinear dynamics.\n",
        "        To control it effectively, I need to:\n",
        "        1. Counteract the nonlinear damping term μ(1-x²)v\n",
        "        2. Add appropriate control to stabilize the system toward the origin\n",
        "        3. Ensure the state stays within constraints [-2,2] and controls within [-5,5]\n",
        "\n",
        "        I'll use a model-predictive approach with a quadratic cost function that penalizes:\n",
        "        - Deviation from the origin (state cost)\n",
        "        - Excessive control effort (control cost)\n",
        "        - With increasing weight on errors as we approach the final time\n",
        "\n",
        "        This results in a smooth control sequence that navigates the nonlinear dynamics\n",
        "        to bring the system to rest at the origin.\"\"\"\n",
        "        \n",
        "        # Format control values\n",
        "        control_str = \", \".join([f\"{u:.3f}\" for u in control_inputs])\n",
        "        \n",
        "        # Create output\n",
        "        complete_output = f\"{reasoning_start}{reasoning}{reasoning_end}{solution_start}{control_str}{solution_end}\"\n",
        "        \n",
        "        # Add to dataset\n",
        "        data.append({\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": vdp_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": problem}\n",
        "            ],\n",
        "            \"answer\": control_str,\n",
        "            \"Messages\": [\n",
        "                {\"role\": \"system\", \"content\": vdp_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": problem},\n",
        "                {\"role\": \"assistant\", \"content\": complete_output}\n",
        "            ],\n",
        "            \"system_type\": \"van_der_pol\"\n",
        "        })\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Define regex pattern to match control sequence\n",
        "solution_end_regex = r\"</CONTROLS>[\\s]{0,}\" + \\\n",
        "    \"(?:\" + re.escape(tokenizer.eos_token) + \")?\"\n",
        "\n",
        "match_format = re.compile(\n",
        "    rf\"{reasoning_end}.*?\"\\\n",
        "    rf\"{solution_start}(.+?){solution_end_regex}\"\\\n",
        "    rf\"[\\s]{{0,}}$\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")\n",
        "\n",
        "def match_format_exactly(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        if match_format.search(response) is not None: score += 3.0\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "def match_format_approximately(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        score += 0.5 if response.count(reasoning_end) == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_start) == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_end) == 1 else -1.0\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5NI47rOIRP2"
      },
      "source": [
        "Check to see if it worked:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHV9BXYiIYaq"
      },
      "source": [
        "Let's truncate the pre fine-tuning dataset to `max_seq_length/2` since we don't want too long reasoning traces.\n",
        "\n",
        "Note this might take 2 minutes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6NkUCAGIj8N"
      },
      "source": [
        "We then tokenize the messages and convert it to a Hugging Face compatible dataset format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_control_sequence(prompts, completions, answer, **kwargs):\n",
        "    \"\"\"Evaluates control sequences with extreme emphasis on terminal state accuracy.\"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    # Quadratic reward matrices with stronger position emphasis\n",
        "    Q = np.diag([25.0, 5.0])  # Much higher weight on position vs velocity\n",
        "    R = 0.05                  # Reduced control cost to encourage more aggressive control\n",
        "    \n",
        "    # Terminal state parameters with much higher values\n",
        "    position_terminal_weight = 50.0   # Significantly increased emphasis on final position\n",
        "    velocity_terminal_weight = 25.0   # Increased emphasis on final velocity\n",
        "    terminal_precision = 50.0         # Much sharper gradient near origin\n",
        "    \n",
        "    for completion, true_answer in zip(completions, answer):\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        \n",
        "        # Extract control sequence\n",
        "        control_match = re.search(rf\"{solution_start}(.*?){solution_end}\", response, re.DOTALL)\n",
        "        if control_match is None:\n",
        "            scores.append(-5.0)  # Stronger penalty\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            # Parse control values\n",
        "            control_text = control_match.group(1).strip()\n",
        "            control_values = [float(x.strip()) for x in control_text.split(',')]\n",
        "            \n",
        "            # Basic constraints checks with moderate rewards\n",
        "            if len(control_values) == steps:\n",
        "                score += 1.0\n",
        "            else:\n",
        "                score -= 2.0\n",
        "                \n",
        "            if all(-3 <= u <= 3 for u in control_values):\n",
        "                score += 0.5\n",
        "            else:\n",
        "                score -= 3.0\n",
        "            \n",
        "            # Parse initial state\n",
        "            problem_text = prompts[0][-1][\"content\"]\n",
        "            initial_match = re.search(r\"position=([-\\d\\.]+), velocity=([-\\d\\.]+)\", problem_text)\n",
        "            if initial_match:\n",
        "                x0 = float(initial_match.group(1))\n",
        "                v0 = float(initial_match.group(2))\n",
        "                initial_error = np.sqrt(x0**2 + v0**2)\n",
        "                \n",
        "                # Simulate trajectory\n",
        "                x, v = x0, v0\n",
        "                valid_trajectory = True\n",
        "                total_quad_reward = 0.0\n",
        "                trajectory_states = [(x, v)]\n",
        "                \n",
        "                for i, u in enumerate(control_values):\n",
        "                    # Apply control\n",
        "                    v = v + u * dt\n",
        "                    x = x + v * dt\n",
        "                    trajectory_states.append((x, v))\n",
        "                    \n",
        "                    # Check constraints\n",
        "                    if not (-1 <= x <= 1 and -1 <= v <= 1):\n",
        "                        valid_trajectory = False\n",
        "                        break\n",
        "                    \n",
        "                    # Calculate LQR-style quadratic rewards\n",
        "                    state_vector = np.array([[x], [v]])\n",
        "                    state_quad_reward = -float(state_vector.T @ Q @ state_vector)\n",
        "                    control_quad_reward = -(R * u**2)\n",
        "                    \n",
        "                    # Cubic time weighting to heavily emphasize final states\n",
        "                    time_weight = 1.0 + (i / steps)**3  \n",
        "                    step_reward = time_weight * (state_quad_reward + control_quad_reward)\n",
        "                    total_quad_reward += step_reward\n",
        "                \n",
        "                # Basic valid trajectory check\n",
        "                if valid_trajectory:\n",
        "                    score += 1.0\n",
        "                else:\n",
        "                    score -= 5.0  # Stronger penalty for constraint violations\n",
        "                \n",
        "                # Final state with extreme precision rewards\n",
        "                final_x, final_v = trajectory_states[-1]\n",
        "                final_error = np.sqrt(final_x**2 + final_v**2)\n",
        "                \n",
        "                # Exponential terminal rewards with sharper falloff\n",
        "                position_reward = position_terminal_weight * np.exp(-terminal_precision * final_x**2)\n",
        "                velocity_reward = velocity_terminal_weight * np.exp(-terminal_precision * final_v**2)\n",
        "                score += position_reward + velocity_reward\n",
        "                \n",
        "                # Power law terminal reward - creates even sharper gradient at origin\n",
        "                if abs(final_x) < 0.1:  # Only apply for somewhat close trajectories\n",
        "                    precision_multiplier = 40.0  # Scale factor\n",
        "                    position_power_reward = precision_multiplier / (1 + 100 * abs(final_x)**1.5)\n",
        "                    score += position_power_reward\n",
        "                \n",
        "                # Much more aggressive tiered rewards\n",
        "                if abs(final_x) < 0.005 and abs(final_v) < 0.005:  # Extremely precise\n",
        "                    score += 30.0\n",
        "                elif abs(final_x) < 0.01 and abs(final_v) < 0.01:  # Very precise\n",
        "                    score += 20.0\n",
        "                elif abs(final_x) < 0.05 and abs(final_v) < 0.05:\n",
        "                    score += 10.0\n",
        "                elif abs(final_x) < 0.1 and abs(final_v) < 0.1:\n",
        "                    score += 5.0\n",
        "                \n",
        "                # Penalize poor terminal state more aggressively\n",
        "                if abs(final_x) > 0.2 or abs(final_v) > 0.2:\n",
        "                    score -= 5.0 * (abs(final_x) + abs(final_v))\n",
        "            \n",
        "            scores.append(score)\n",
        "            \n",
        "        except Exception as e:\n",
        "            scores.append(-3.0)\n",
        "            \n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAQJjQrYKzOk"
      },
      "source": [
        "Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate combined dataset with both double integrator and Van der Pol systems\n",
        "combined_data = generate_combined_control_dataset(num_samples_per_system=200)\n",
        "from datasets import Dataset\n",
        "combined_dataset = Dataset.from_list(combined_data)\n",
        "\n",
        "# Format dataset properly for SFT training\n",
        "def format_for_sft(example):\n",
        "    # Create a prompt without the assistant's response\n",
        "    # Use system-specific prompt from the example (not the global system_prompt)\n",
        "    system_content = example[\"Messages\"][0][\"content\"]\n",
        "    \n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": example[\"Messages\"][1][\"content\"]}\n",
        "        ],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    \n",
        "    # Get the full conversation including assistant's response\n",
        "    full_text = tokenizer.apply_chat_template(\n",
        "        example[\"Messages\"],\n",
        "        tokenize=False\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"text\": full_text,\n",
        "        \"system_type\": example.get(\"system_type\", \"unknown\")\n",
        "    }\n",
        "\n",
        "# Apply the formatting\n",
        "combined_dataset = combined_dataset.map(format_for_sft)\n",
        "\n",
        "# Print dataset statistics\n",
        "di_samples = len([x for x in combined_dataset if x[\"system_type\"] == \"double_integrator\"])\n",
        "vdp_samples = len([x for x in combined_dataset if x[\"system_type\"] == \"van_der_pol\"])\n",
        "print(f\"Dataset statistics:\")\n",
        "print(f\"Total samples: {len(combined_dataset)}\")\n",
        "print(f\"Double integrator samples: {di_samples}\")\n",
        "print(f\"Van der Pol samples: {vdp_samples}\")\n",
        "\n",
        "# Split data for train/eval if needed (80% train, 20% eval)\n",
        "combined_dataset = combined_dataset.shuffle(seed=42)\n",
        "split_dataset = combined_dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "eval_dataset = split_dataset[\"test\"]\n",
        "\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation set size: {len(eval_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Pre fine-tune the model to learn both system formats\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Create training arguments (instead of SFTConfig)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./control-format-model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    warmup_steps=10,\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=5,\n",
        "    eval_steps=100,\n",
        "    optim=\"adamw_8bit\",\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    seed=3407,\n",
        "    report_to=\"wandb\",\n",
        ")\n",
        "\n",
        "# Create the trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=training_args,\n",
        "    dataset_text_field=\"text\",  # This goes as a parameter to SFTTrainer, not in args\n",
        ")\n",
        "\n",
        "# Run pre-training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_prompt_length = maximum_length + 1 # + 1 just in case!\n",
        "max_completion_length = 2048\n",
        "\n",
        "from vllm import SamplingParams\n",
        "vllm_sampling_params = SamplingParams(\n",
        "    min_p = 0.1,\n",
        "    top_p = 1.0,\n",
        "    top_k = -1,\n",
        "    seed = 3407,\n",
        "    stop = [tokenizer.eos_token],\n",
        "    include_stop_str_in_output = True,\n",
        ")\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    vllm_sampling_params = vllm_sampling_params,\n",
        "    temperature = 1.0,\n",
        "    learning_rate = 5e-6,\n",
        "    weight_decay = 0.01,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    per_device_train_batch_size = 8,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 8, # Decrease if out of memory\n",
        "    max_completion_length = max_completion_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps =50,\n",
        "    save_steps = 500,\n",
        "    report_to = \"wandb\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # fp16_full_eval = True,\n",
        "    # per_device_eval_batch_size = 4,\n",
        "    # eval_accumulation_steps = 1,\n",
        "    # eval_strategy = \"steps\",\n",
        "    # eval_steps = 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now run GRPO training with the combined dataset\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=[\n",
        "        match_format_exactly,\n",
        "        match_format_approximately,\n",
        "    ],\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model with a name indicating it handles both systems\n",
        "model.save_lora(\"di_vdp_control_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Test with a specific problem (similar update for inference after loading)\n",
        "# For inference, you need to decide the dt and steps for the query\n",
        "infer_dt_loaded = dt\n",
        "infer_steps_loaded = steps\n",
        "infer_total_time_loaded = infer_dt_loaded * infer_steps_loaded\n",
        "\n",
        "# Create the system prompt for this specific inference call\n",
        "current_infer_system_prompt_loaded = get_system_prompt(infer_dt_loaded, infer_steps_loaded)\n",
        "\n",
        "test_prompt_loaded = f\"Control a double integrator system with initial state [position=0.5, velocity=-0.3] to reach the origin (0,0) in {infer_total_time_loaded:.2f} seconds using {infer_steps_loaded} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": test_prompt_loaded},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params=sampling_params,\n",
        "    lora_request=None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "# print(messages)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Test with a specific problem\n",
        "test_prompt = \"Control a double integrator system with initial state [position=0.5, velocity=-0.3] to reach the origin (0,0) in 5 seconds. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": test_prompt},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params=sampling_params,\n",
        "    lora_request=model.load_lora(\"di_vdp_control_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "print(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_controls_from_response(response_text):\n",
        "    \"\"\"Extract control values from model response using regex.\"\"\"\n",
        "    import re\n",
        "    \n",
        "    # Extract control sequence\n",
        "    control_match = re.search(r\"<CONTROLS>(.*?)</CONTROLS>\", response_text, re.DOTALL)\n",
        "    \n",
        "    if control_match is None:\n",
        "        print(\"ERROR: Could not extract control values from response\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        # Parse control values\n",
        "        control_text = control_match.group(1).strip()\n",
        "        control_values = [float(x.strip()) for x in control_text.split(',')]\n",
        "        return control_values\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR parsing control values: {e}\")\n",
        "        return None\n",
        "    \n",
        "def generate_model_controls(model, tokenizer, initial_positions, initial_velocities, dt, steps):\n",
        "    \"\"\"Run inference with the trained model on multiple initial conditions.\"\"\"\n",
        "    model_controls = []\n",
        "    system_prompt = get_system_prompt(dt, steps)\n",
        "    total_time = dt * steps\n",
        "    \n",
        "    for x0, v0 in zip(initial_positions, initial_velocities):\n",
        "        # Construct prompt\n",
        "        test_prompt = f\"Control a double integrator system with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time:.2f} seconds using {steps} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "        \n",
        "        # Prepare chat message format\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": test_prompt},\n",
        "        ]\n",
        "        \n",
        "        # Format with chat template\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False,\n",
        "        )\n",
        "        \n",
        "        # Run inference\n",
        "        from vllm import SamplingParams\n",
        "        sampling_params = SamplingParams(\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            max_tokens=1024,\n",
        "        )\n",
        "        \n",
        "        # Use the fine-tuned model with loaded LoRA weights\n",
        "        output = model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"di_vdp_control_lora\"),\n",
        "        )[0].outputs[0].text\n",
        "        \n",
        "        # Extract control values\n",
        "        controls = extract_controls_from_response(output)\n",
        "        if controls:\n",
        "            model_controls.append(controls)\n",
        "        else:\n",
        "            print(f\"Failed to extract controls for initial state: pos={x0:.2f}, vel={v0:.2f}\")\n",
        "            # Use LQR solution as fallback\n",
        "            model_controls.append(solve_double_integrator(x0, v0, dt, steps))\n",
        "    \n",
        "    return model_controls\n",
        "\n",
        "def simulate_trajectories(initial_states, control_sequences, dt):\n",
        "    \"\"\"Simulate system trajectories for given initial states and control sequences.\"\"\"\n",
        "    trajectories = []\n",
        "    \n",
        "    for (x0, v0), controls in zip(initial_states, control_sequences):\n",
        "        x, v = x0, v0\n",
        "        positions = [x]\n",
        "        velocities = [v]\n",
        "        times = [0]\n",
        "        \n",
        "        for i, u in enumerate(controls):\n",
        "            # Apply control input\n",
        "            v = v + u * dt\n",
        "            x = x + v * dt\n",
        "            \n",
        "            # Store state\n",
        "            positions.append(x)\n",
        "            velocities.append(v)\n",
        "            times.append((i+1) * dt)\n",
        "        \n",
        "        trajectories.append({\n",
        "            'times': times,\n",
        "            'positions': positions,\n",
        "            'velocities': velocities,\n",
        "            'controls': controls,\n",
        "            'final_error': (positions[-1]**2 + velocities[-1]**2)**0.5\n",
        "        })\n",
        "    \n",
        "    return trajectories\n",
        "\n",
        "def evaluate_and_visualize(model, tokenizer, num_test_cases=5):\n",
        "    \"\"\"Compare model's control solutions with optimal LQR solutions.\"\"\"\n",
        "    # Generate random initial conditions for testing\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    test_positions = np.random.uniform(-0.8, 0.8, num_test_cases)\n",
        "    test_velocities = np.random.uniform(-0.8, 0.8, num_test_cases)\n",
        "    initial_states = list(zip(test_positions, test_velocities))\n",
        "    \n",
        "    # Generate LQR solutions (ground truth)\n",
        "    lqr_controls = [solve_double_integrator(x0, v0, dt, steps) for x0, v0 in initial_states]\n",
        "    \n",
        "    # Generate model solutions\n",
        "    model_controls = generate_model_controls(\n",
        "        model, tokenizer, test_positions, test_velocities, dt, steps\n",
        "    )\n",
        "    \n",
        "    # Simulate both solutions\n",
        "    lqr_trajectories = simulate_trajectories(initial_states, lqr_controls, dt)\n",
        "    model_trajectories = simulate_trajectories(initial_states, model_controls, dt)\n",
        "    \n",
        "    # Calculate evaluation metrics\n",
        "    lqr_final_errors = [traj['final_error'] for traj in lqr_trajectories]\n",
        "    model_final_errors = [traj['final_error'] for traj in model_trajectories]\n",
        "    \n",
        "    print(\"\\n=== Evaluation Results ===\")\n",
        "    print(f\"Average LQR final error: {np.mean(lqr_final_errors):.6f}\")\n",
        "    print(f\"Average Model final error: {np.mean(model_final_errors):.6f}\")\n",
        "    \n",
        "    # Plot comparison\n",
        "    plot_comparison(initial_states, lqr_trajectories, model_trajectories, dt)\n",
        "    \n",
        "    return lqr_trajectories, model_trajectories\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_comparison(initial_states, lqr_trajectories, model_trajectories, dt):\n",
        "    \"\"\"Plot comparison between LQR and model trajectories.\"\"\"\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(14, 12))\n",
        "    \n",
        "    # Plot settings\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(initial_states)))\n",
        "    \n",
        "    for i, ((x0, v0), lqr_traj, model_traj, color) in enumerate(zip(\n",
        "        initial_states, lqr_trajectories, model_trajectories, colors)):\n",
        "        \n",
        "        # Position plot\n",
        "        axs[0].plot(lqr_traj['times'], lqr_traj['positions'], 'b-', label='LQR')\n",
        "        axs[0].plot(model_traj['times'], model_traj['positions'], 'r--', marker='.', label='Model')\n",
        "        axs[0].axhline(y=-1, color='r', linestyle=':')\n",
        "        axs[0].axhline(y=1, color='r', linestyle=':')\n",
        "        axs[0].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].set_title('Position Trajectories (Solid=LQR, Dashed=Model)')\n",
        "        axs[0].set_ylabel('Position')\n",
        "        axs[0].legend()\n",
        "        \n",
        "        # Velocity plot\n",
        "        axs[1].plot(lqr_traj['times'], lqr_traj['velocities'], 'g-', label='LQR')\n",
        "        axs[1].plot(model_traj['times'], model_traj['velocities'], 'r--', marker='.', label='Model')\n",
        "        axs[1].axhline(y=-1, color='r', linestyle=':')\n",
        "        axs[1].axhline(y=1, color='r', linestyle=':')\n",
        "        axs[1].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].set_ylabel('Velocity')\n",
        "        axs[1].legend()\n",
        "        \n",
        "        # Control plot\n",
        "        axs[2].step(lqr_traj['times'][:-1], lqr_traj['controls'], 'b-', where='post', label='LQR')\n",
        "        axs[2].step(model_traj['times'][:-1], model_traj['controls'], 'r--', marker='.', where='post', label='Model')\n",
        "        axs[2].axhline(y=-3, color='r', linestyle=':')\n",
        "        axs[2].axhline(y=3, color='r', linestyle=':')\n",
        "        axs[2].grid(True)\n",
        "        axs[2].set_xlabel('Time (s)')\n",
        "        axs[2].set_ylabel('Control Input')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(hspace=0.3)\n",
        "        plt.show()\n",
        "        \n",
        "        # Phase portrait\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        \n",
        "        # Draw state bounds as a rectangle\n",
        "        plt.plot([x[0] for x in initial_states], [x[1] for x in initial_states], 'go', label='Initial States')\n",
        "        plt.plot(lqr_traj['positions'], lqr_traj['velocities'], 'b-', label='LQR')\n",
        "        plt.plot(model_traj['positions'], model_traj['velocities'], 'r--', marker='.', label='Model')\n",
        "        \n",
        "        # Mark origin with a star\n",
        "        plt.plot(0, 0, '*', color='k', markersize=12, label='Target')\n",
        "        \n",
        "        plt.axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        plt.axvline(x=0, color='k', linestyle='-', alpha=0.5)\n",
        "        plt.grid(True)\n",
        "        plt.title('Phase Portrait (Position vs. Velocity)')\n",
        "        plt.xlabel('Position')\n",
        "        plt.ylabel('Velocity')\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "    \n",
        "    # Print overall statistics\n",
        "    print(\"=== Overall Statistics ===\")\n",
        "    for i, ((x0, v0), lqr_traj, model_traj) in enumerate(zip(initial_states, lqr_trajectories, model_trajectories)):\n",
        "        lqr_final_pos = lqr_traj['positions'][-1]\n",
        "        lqr_final_vel = lqr_traj['velocities'][-1]\n",
        "        model_final_pos = model_traj['positions'][-1]\n",
        "        model_final_vel = model_traj['velocities'][-1];\n",
        "        \n",
        "        print(f\"Case {i+1}: Initial({x0:.2f}, {v0:.2f}) → \"\n",
        "              f\"LQR Final({lqr_final_pos:.3f}, {lqr_final_vel:.3f}), \"\n",
        "              f\"Model Final({model_final_pos:.3f}, {model_final_vel:.3f}), \"\n",
        "              f\"Error(LQR: {lqr_traj['final_error']:.3f}, Model: {model_traj['final_error']:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_model_controls_mpc(model, tokenizer, initial_x, initial_v, dt, prediction_horizon, num_simulation_steps, lora_request, sampling_params):\n",
        "    \"\"\"\n",
        "    Run MPC-style inference with the trained model.\n",
        "    At each step, predict a sequence of 'prediction_horizon' controls,\n",
        "    but only apply the first one.\n",
        "    \"\"\"\n",
        "    current_x, current_v = initial_x, initial_v\n",
        "    \n",
        "    applied_controls_sequence = []\n",
        "    positions_history = [current_x]\n",
        "    velocities_history = [current_v]\n",
        "    times_history = [0.0]\n",
        "\n",
        "    for k_sim_step in range(num_simulation_steps):\n",
        "        # System prompt for the model's prediction task at this MPC step\n",
        "        mpc_system_prompt = get_system_prompt(dt, prediction_horizon)\n",
        "        total_prediction_time = dt * prediction_horizon\n",
        "        \n",
        "        # User prompt for the current state\n",
        "        current_test_prompt = f\"Control a double integrator system with initial state [position={current_x:.2f}, velocity={current_v:.2f}] to reach the origin (0,0) in {total_prediction_time:.2f} seconds using {prediction_horizon} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "        \n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": mpc_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": current_test_prompt},\n",
        "        ]\n",
        "        \n",
        "        text_input = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False,\n",
        "        )\n",
        "        \n",
        "        output_text = model.fast_generate(\n",
        "            text_input,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=lora_request,\n",
        "        )[0].outputs[0].text\n",
        "        \n",
        "        predicted_controls_at_step = extract_controls_from_response(output_text)\n",
        "        \n",
        "        u_to_apply = None\n",
        "        if predicted_controls_at_step and len(predicted_controls_at_step) > 0:\n",
        "            u_to_apply = predicted_controls_at_step[0]\n",
        "            # Clamp control input to ensure it's within bounds, even if model doesn't adhere\n",
        "            u_to_apply = max(-3.0, min(3.0, u_to_apply))\n",
        "        else:\n",
        "            print(f\"MPC Step {k_sim_step+1}: Failed to extract controls or empty list for state ({current_x:.2f}, {current_v:.2f}). Falling back to LQR for one step.\")\n",
        "            # # Fallback: use LQR for one step\n",
        "            # # solve_double_integrator computes a sequence, we need the first control for one step.\n",
        "            # lqr_fallback_control_sequence = solve_double_integrator(current_x, current_v, dt, 1)\n",
        "            # if lqr_fallback_control_sequence:\n",
        "            #      u_to_apply = lqr_fallback_control_sequence[0]\n",
        "            # else: # Should not happen if solve_double_integrator is robust\n",
        "            #      u_to_apply = 0.0\n",
        "            # u_to_apply = max(-3.0, min(3.0, u_to_apply))\n",
        "            \n",
        "            u_to_apply = 0.0\n",
        "            u_to_apply = max(-3.0, min(3.0, u_to_apply))            \n",
        "\n",
        "\n",
        "        applied_controls_sequence.append(u_to_apply)\n",
        "        \n",
        "        # Simulate one step forward with the chosen control\n",
        "        # Using v_next for x_next calculation, consistent with existing simulate_trajectories\n",
        "        current_v = current_v + u_to_apply * dt \n",
        "        current_x = current_x + current_v * dt \n",
        "        \n",
        "        # Clamp states to ensure they remain within bounds\n",
        "        current_x = max(-1.0, min(1.0, current_x))\n",
        "        current_v = max(-1.0, min(1.0, current_v))\n",
        "        \n",
        "        positions_history.append(current_x)\n",
        "        velocities_history.append(current_v)\n",
        "        times_history.append((k_sim_step + 1) * dt)\n",
        "\n",
        "    final_error = (positions_history[-1]**2 + velocities_history[-1]**2)**0.5\n",
        "    \n",
        "    return {\n",
        "        'times': times_history,\n",
        "        'positions': positions_history,\n",
        "        'velocities': velocities_history,\n",
        "        'controls': applied_controls_sequence, # Sequence of controls actually applied\n",
        "        'final_error': final_error\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ...existing code...\n",
        "# # This is an example of how your testing cell (last cell in the screenshot) would be modified:\n",
        "\n",
        "# import matplotlib.pyplot as plt # Ensure plt is imported\n",
        "\n",
        "# # Test with specific initial conditions for better comparison\n",
        "# test_initial_conditions = [\n",
        "#     (0.5, 0.0),    # Position offset only\n",
        "#     (0.0, 0.5),    # Velocity offset only\n",
        "#     (0.5, -0.5),   # Mixed initial condition\n",
        "#     (-0.7, 0.3),   # Another mixed case\n",
        "#     (0.8, 0.8)     # More challenging case\n",
        "# ]\n",
        "\n",
        "# # Extract positions and velocities (not strictly needed if iterating test_initial_conditions directly)\n",
        "# # test_positions = [pos for pos, _ in test_initial_conditions]\n",
        "# # test_velocities = [vel for _, vel in test_initial_conditions]\n",
        "\n",
        "# # --- MPC Model Trajectory Generation ---\n",
        "# # Load LoRA adapter once before the loop\n",
        "# # The name \"di_control_lora\" should match the name used when saving.\n",
        "# try:\n",
        "#     lora_request_for_mpc = model.load_lora(\"di_control_lora\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading LoRA adapter: {e}. Ensure 'di_control_lora' is saved and model is compatible.\")\n",
        "#     # Fallback or define lora_request_for_mpc = None if LoRA is merged or not used.\n",
        "#     # For this MPC setup, assuming LoRA is intended to be used.\n",
        "#     raise\n",
        "\n",
        "# # Define sampling parameters for generation (can be tuned)\n",
        "# mpc_sampling_params = SamplingParams(\n",
        "#     temperature=0.7, # As used in your example\n",
        "#     top_k=50,        # As used in your example\n",
        "#     max_tokens=1024, # As used in your example\n",
        "#     stop = [tokenizer.eos_token], # Good practice\n",
        "#     include_stop_str_in_output = True, # Consistent with GRPO config\n",
        "# )\n",
        "\n",
        "# model_mpc_trajectories = []\n",
        "# print(\"Generating Model MPC trajectories...\")\n",
        "# for i, (x0, v0) in enumerate(test_initial_conditions):\n",
        "#     print(f\"Processing case {i+1}/{len(test_initial_conditions)}: Initial state ({x0:.2f}, {v0:.2f})\")\n",
        "#     # global 'dt' and 'steps' are used.\n",
        "#     # 'steps' is used as prediction_horizon and num_simulation_steps for a fair comparison period.\n",
        "#     mpc_traj = generate_model_controls_mpc(\n",
        "#         model, \n",
        "#         tokenizer, \n",
        "#         x0, \n",
        "#         v0, \n",
        "#         dt,      # Time step\n",
        "#         steps,   # Prediction horizon for each MPC call\n",
        "#         steps,   # Total number of simulation steps for MPC\n",
        "#         lora_request_for_mpc,\n",
        "#         mpc_sampling_params\n",
        "#     )\n",
        "#     model_mpc_trajectories.append(mpc_traj)\n",
        "# print(\"Finished generating Model MPC trajectories.\")\n",
        "\n",
        "# # --- LQR Trajectory Generation (for comparison) ---\n",
        "# # LQR solutions are typically full-horizon optimal for the given 'steps'\n",
        "# lqr_controls_full_horizon = [solve_double_integrator(x0, v0, dt, steps) \n",
        "#                              for x0, v0 in test_initial_conditions]\n",
        "# lqr_trajectories = simulate_trajectories(test_initial_conditions, lqr_controls_full_horizon, dt)\n",
        "\n",
        "\n",
        "# # --- Plot Comparison ---\n",
        "# # Ensure plot_comparison can handle the trajectory dictionary format from generate_model_controls_mpc\n",
        "# # The existing plot_comparison should work if 'steps' used internally matches num_simulation_steps\n",
        "# plot_comparison(test_initial_conditions, lqr_trajectories, model_mpc_trajectories, dt)\n",
        "\n",
        "# # --- Print Summary Statistics ---\n",
        "# lqr_final_errors = [traj['final_error'] for traj in lqr_trajectories]\n",
        "# model_mpc_final_errors = [traj['final_error'] for traj in model_mpc_trajectories] # Use MPC errors\n",
        "\n",
        "# print(\"\\n=== Summary (MPC Model vs Full Horizon LQR) ===\")\n",
        "# for i, ((x0, v0), lqr_err, model_err) in enumerate(zip(\n",
        "#     test_initial_conditions, lqr_final_errors, model_mpc_final_errors)):\n",
        "#     print(f\"Case {i+1} - Initial: ({x0:.2f}, {v0:.2f}) → LQR error: {lqr_err:.6f}, Model MPC error: {model_err:.6f}\")\n",
        "\n",
        "# # ... any further code ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_combined_control_sequence(prompts, completions, answer, **kwargs):\n",
        "    \"\"\"\n",
        "    Evaluates control sequences for either double integrator or Van der Pol system.\n",
        "    Automatically detects system type from the prompt.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    for completion, true_answer in zip(completions, answer):\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        problem_text = prompts[0][-1][\"content\"]\n",
        "        \n",
        "        # Determine system type from problem text\n",
        "        if \"double integrator\" in problem_text.lower():\n",
        "            system_type = \"double_integrator\"\n",
        "            # Position/velocity bounds for double integrator\n",
        "            state_bounds = (-1.0, 1.0)\n",
        "            control_bounds = (-3.0, 3.0)\n",
        "            # Weights for double integrator scoring\n",
        "            position_terminal_weight = 50.0\n",
        "            velocity_terminal_weight = 25.0\n",
        "            Q = np.diag([25.0, 5.0])  # Stronger emphasis on position\n",
        "            R = 0.05                   # Control cost\n",
        "        elif \"van der pol\" in problem_text.lower():\n",
        "            system_type = \"van_der_pol\"\n",
        "            # Position/velocity bounds for Van der Pol\n",
        "            state_bounds = (-2.0, 2.0)\n",
        "            control_bounds = (-5.0, 5.0)\n",
        "            # Weights for Van der Pol scoring\n",
        "            position_terminal_weight = 60.0  # Higher due to more complex dynamics\n",
        "            velocity_terminal_weight = 30.0\n",
        "            Q = np.diag([30.0, 10.0])  # Even stronger emphasis on position vs velocity\n",
        "            R = 0.1                    # Control cost\n",
        "        else:\n",
        "            scores.append(-10.0)  # Unknown system type\n",
        "            continue\n",
        "        \n",
        "        # Extreme terminal precision parameter (same for both systems)\n",
        "        terminal_precision = 50.0\n",
        "        \n",
        "        # Extract control sequence\n",
        "        control_match = re.search(rf\"{solution_start}(.*?){solution_end}\", response, re.DOTALL)\n",
        "        if control_match is None:\n",
        "            scores.append(-5.0)  # Strong penalty for missing control section\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            # Parse control values\n",
        "            control_text = control_match.group(1).strip()\n",
        "            control_values = [float(x.strip()) for x in control_text.split(',')]\n",
        "            \n",
        "            # Basic constraints checks\n",
        "            if len(control_values) == steps:\n",
        "                score += 1.0\n",
        "            else:\n",
        "                score -= 2.0\n",
        "                \n",
        "            # Check if controls are within bounds\n",
        "            control_min, control_max = control_bounds\n",
        "            if all(control_min <= u <= control_max for u in control_values):\n",
        "                score += 0.5\n",
        "            else:\n",
        "                score -= 3.0\n",
        "            \n",
        "            # Parse initial state from problem text\n",
        "            initial_match = re.search(r\"position=([-\\d\\.]+), velocity=([-\\d\\.]+)\", problem_text)\n",
        "            if initial_match:\n",
        "                x0 = float(initial_match.group(1))\n",
        "                v0 = float(initial_match.group(2))\n",
        "                \n",
        "                # Simulate trajectory for the appropriate system\n",
        "                x, v = x0, v0\n",
        "                valid_trajectory = True\n",
        "                total_quad_reward = 0.0\n",
        "                trajectory_states = [(x, v)]\n",
        "                \n",
        "                for i, u in enumerate(control_values):\n",
        "                    # Apply control based on system type\n",
        "                    if system_type == \"double_integrator\":\n",
        "                        # Double integrator dynamics: ẋ = v, v̇ = u\n",
        "                        v = v + u * dt\n",
        "                        x = x + v * dt\n",
        "                    elif system_type == \"van_der_pol\":\n",
        "                        # Van der Pol dynamics: ẋ - μ(1-x²)ẋ + x = u\n",
        "                        mu = 1.0  # Standard value\n",
        "                        from scipy.integrate import solve_ivp\n",
        "                        \n",
        "                        def vdp_dynamics(t, state, u_val):\n",
        "                            x_val, v_val = state\n",
        "                            dxdt = v_val\n",
        "                            dvdt = mu * (1 - x_val**2) * v_val - x_val + u_val\n",
        "                            return [dxdt, dvdt]\n",
        "                        \n",
        "                        # Simulate one step with 4th order integration\n",
        "                        sol = solve_ivp(\n",
        "                            lambda t, y: vdp_dynamics(t, y, u), \n",
        "                            [0, dt], [x, v], method='RK45', t_eval=[dt]\n",
        "                        )\n",
        "                        x, v = sol.y[:, -1].tolist()\n",
        "                    \n",
        "                    trajectory_states.append((x, v))\n",
        "                    \n",
        "                    # Check constraints (different for each system)\n",
        "                    state_min, state_max = state_bounds\n",
        "                    if not (state_min <= x <= state_max and state_min <= v <= state_max):\n",
        "                        valid_trajectory = False\n",
        "                        break\n",
        "                    \n",
        "                    # Calculate quadratic rewards\n",
        "                    state_vector = np.array([[x], [v]])\n",
        "                    state_quad_reward = -float(state_vector.T @ Q @ state_vector)\n",
        "                    control_quad_reward = -(R * u**2)\n",
        "                    \n",
        "                    # Cubic time weighting to heavily emphasize final states\n",
        "                    time_weight = 1.0 + (i / steps)**3  \n",
        "                    step_reward = time_weight * (state_quad_reward + control_quad_reward)\n",
        "                    total_quad_reward += step_reward\n",
        "                \n",
        "                # Basic valid trajectory check\n",
        "                if valid_trajectory:\n",
        "                    score += 1.0\n",
        "                else:\n",
        "                    score -= 5.0  # Stronger penalty for constraint violations\n",
        "                \n",
        "                # Final state rewards\n",
        "                final_x, final_v = trajectory_states[-1]\n",
        "                final_error = np.sqrt(final_x**2 + final_v**2)\n",
        "                \n",
        "                # Exponential terminal rewards with sharp falloff\n",
        "                position_reward = position_terminal_weight * np.exp(-terminal_precision * final_x**2)\n",
        "                velocity_reward = velocity_terminal_weight * np.exp(-terminal_precision * final_v**2)\n",
        "                score += position_reward + velocity_reward\n",
        "                \n",
        "                # Power law terminal reward - creates even sharper gradient at origin\n",
        "                if abs(final_x) < 0.1:  # Only apply for somewhat close trajectories\n",
        "                    precision_multiplier = 40.0  # Scale factor\n",
        "                    position_power_reward = precision_multiplier / (1 + 100 * abs(final_x)**1.5)\n",
        "                    score += position_power_reward\n",
        "                \n",
        "                # Tiered rewards based on final precision\n",
        "                if abs(final_x) < 0.005 and abs(final_v) < 0.005:  # Extremely precise\n",
        "                    score += 30.0\n",
        "                elif abs(final_x) < 0.01 and abs(final_v) < 0.01:  # Very precise\n",
        "                    score += 20.0\n",
        "                elif abs(final_x) < 0.05 and abs(final_v) < 0.05:\n",
        "                    score += 10.0\n",
        "                elif abs(final_x) < 0.1 and abs(final_v) < 0.1:\n",
        "                    score += 5.0\n",
        "                \n",
        "                # Penalize poor terminal state more aggressively\n",
        "                if abs(final_x) > 0.2 or abs(final_v) > 0.2:\n",
        "                    score -= 5.0 * (abs(final_x) + abs(final_v))\n",
        "            \n",
        "            scores.append(score)\n",
        "            \n",
        "        except Exception as e:\n",
        "            scores.append(-3.0)\n",
        "            \n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_van_der_pol(initial_state, control_sequence, dt, mu=1.0):\n",
        "    \"\"\"\n",
        "    Simulate Van der Pol oscillator with the given control sequence.\n",
        "    \n",
        "    Args:\n",
        "        initial_state: Tuple (x0, v0) with initial position and velocity\n",
        "        control_sequence: List of control inputs\n",
        "        dt: Time step size\n",
        "        mu: Damping parameter for Van der Pol (default=1.0)\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with trajectory information\n",
        "    \"\"\"\n",
        "    from scipy.integrate import solve_ivp\n",
        "    \n",
        "    # Initial state\n",
        "    x0, v0 = initial_state\n",
        "    \n",
        "    # Define Van der Pol dynamics with control\n",
        "    def vdp_dynamics(t, state, u):\n",
        "        x, v = state\n",
        "        dxdt = v\n",
        "        dvdt = mu * (1 - x**2) * v - x + u\n",
        "        return [dxdt, dvdt]\n",
        "    \n",
        "    # Simulate trajectory\n",
        "    x, v = x0, v0\n",
        "    positions = [x]\n",
        "    velocities = [v]\n",
        "    times = [0]\n",
        "    \n",
        "    for i, u in enumerate(control_sequence):\n",
        "        # Bound control within limits for Van der Pol\n",
        "        u_clamped = max(-5.0, min(5.0, u))\n",
        "        \n",
        "        # Simulate one step with Runge-Kutta integration\n",
        "        sol = solve_ivp(\n",
        "            lambda t, y: vdp_dynamics(t, y, u_clamped),\n",
        "            [0, dt], [x, v], method='RK45', t_eval=[dt]\n",
        "        )\n",
        "        \n",
        "        x, v = sol.y[:, -1].tolist()\n",
        "        \n",
        "        # Bound states if needed (though control should keep it within bounds)\n",
        "        x = max(-2.0, min(2.0, x))\n",
        "        v = max(-2.0, min(2.0, v))\n",
        "        \n",
        "        positions.append(x)\n",
        "        velocities.append(v)\n",
        "        times.append((i+1) * dt)\n",
        "    \n",
        "    return {\n",
        "        'times': times,\n",
        "        'positions': positions,\n",
        "        'velocities': velocities,\n",
        "        'controls': control_sequence,\n",
        "        'final_error': (positions[-1]**2 + velocities[-1]**2)**0.5\n",
        "    }\n",
        "\n",
        "def simulate_double_integrator(initial_state, control_sequence, dt):\n",
        "    \"\"\"\n",
        "    Simulate double integrator with the given control sequence.\n",
        "    \n",
        "    Args:\n",
        "        initial_state: Tuple (x0, v0) with initial position and velocity\n",
        "        control_sequence: List of control inputs\n",
        "        dt: Time step size\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with trajectory information\n",
        "    \"\"\"\n",
        "    # Initial state\n",
        "    x0, v0 = initial_state\n",
        "    \n",
        "    # Simulate trajectory\n",
        "    x, v = x0, v0\n",
        "    positions = [x]\n",
        "    velocities = [v]\n",
        "    times = [0]\n",
        "    \n",
        "    for i, u in enumerate(control_sequence):\n",
        "        # Bound control within limits for double integrator\n",
        "        u_clamped = max(-3.0, min(3.0, u))\n",
        "        \n",
        "        # Apply simple Euler integration for double integrator\n",
        "        v = v + u_clamped * dt\n",
        "        x = x + v * dt\n",
        "        \n",
        "        # Bound states if needed\n",
        "        x = max(-1.0, min(1.0, x))\n",
        "        v = max(-1.0, min(1.0, v))\n",
        "        \n",
        "        positions.append(x)\n",
        "        velocities.append(v)\n",
        "        times.append((i+1) * dt)\n",
        "    \n",
        "    return {\n",
        "        'times': times,\n",
        "        'positions': positions,\n",
        "        'velocities': velocities,\n",
        "        'controls': control_sequence,\n",
        "        'final_error': (positions[-1]**2 + velocities[-1]**2)**0.5\n",
        "    }\n",
        "\n",
        "def generate_model_controls_for_system(model, tokenizer, system_type, initial_positions, initial_velocities, dt, steps, lora_path=None):\n",
        "    \"\"\"\n",
        "    Generate control sequences using the trained model for a specific system type.\n",
        "    \n",
        "    Args:\n",
        "        model: The trained model\n",
        "        tokenizer: The tokenizer\n",
        "        system_type: Either \"double_integrator\" or \"van_der_pol\"\n",
        "        initial_positions: List of initial positions\n",
        "        initial_velocities: List of initial velocities\n",
        "        dt: Time step size\n",
        "        steps: Number of control steps\n",
        "        lora_path: Path to the LoRA weights (optional)\n",
        "    \n",
        "    Returns:\n",
        "        List of control sequences\n",
        "    \"\"\"\n",
        "    model_controls = []\n",
        "    total_time = dt * steps\n",
        "    \n",
        "    # Load LoRA if specified\n",
        "    lora_request = None\n",
        "    if lora_path:\n",
        "        try:\n",
        "            lora_request = model.load_lora(lora_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load LoRA from {lora_path}: {e}\")\n",
        "    \n",
        "    for x0, v0 in zip(initial_positions, initial_velocities):\n",
        "        # Get system-specific system prompt\n",
        "        system_prompt = get_system_prompt(dt, steps, system_type)\n",
        "        \n",
        "        # Construct appropriate prompt based on system type\n",
        "        if system_type == \"double_integrator\":\n",
        "            test_prompt = f\"Control a double integrator system with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time:.2f} seconds using {steps} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "        elif system_type == \"van_der_pol\":\n",
        "            test_prompt = f\"Control a Van der Pol oscillator system (μ=1) with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time:.2f} seconds using {steps} steps. Ensure all states remain within [-2,2] and controls within [-5,5].\"\n",
        "        \n",
        "        # Prepare chat message format\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": test_prompt},\n",
        "        ]\n",
        "        \n",
        "        # Format with chat template\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False,\n",
        "        )\n",
        "        \n",
        "        # Run inference\n",
        "        from vllm import SamplingParams\n",
        "        sampling_params = SamplingParams(\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            max_tokens=1024,\n",
        "        )\n",
        "        \n",
        "        # Use the model with optional LoRA weights\n",
        "        output = model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=lora_request,\n",
        "        )[0].outputs[0].text\n",
        "        \n",
        "        # Extract control values\n",
        "        controls = extract_controls_from_response(output)\n",
        "        if controls:\n",
        "            model_controls.append(controls)\n",
        "        else:\n",
        "            print(f\"Failed to extract controls for {system_type} with initial state: pos={x0:.2f}, vel={v0:.2f}\")\n",
        "            # Use appropriate solver as fallback based on system type\n",
        "            if system_type == \"double_integrator\":\n",
        "                fallback_controls = solve_double_integrator(x0, v0, dt, steps)\n",
        "            else:  # van_der_pol\n",
        "                fallback_controls = solve_van_der_pol(x0, v0, 1.0, dt, steps)\n",
        "            model_controls.append(fallback_controls)\n",
        "    \n",
        "    return model_controls\n",
        "\n",
        "def simulate_trajectories_by_system(system_type, initial_states, control_sequences, dt):\n",
        "    \"\"\"\n",
        "    Simulate system trajectories based on system type.\n",
        "    \n",
        "    Args:\n",
        "        system_type: Either \"double_integrator\" or \"van_der_pol\"\n",
        "        initial_states: List of (position, velocity) tuples\n",
        "        control_sequences: List of control input sequences\n",
        "        dt: Time step size\n",
        "    \n",
        "    Returns:\n",
        "        List of trajectory dictionaries\n",
        "    \"\"\"\n",
        "    trajectories = []\n",
        "    \n",
        "    for (x0, v0), controls in zip(initial_states, control_sequences):\n",
        "        if system_type == \"double_integrator\":\n",
        "            traj = simulate_double_integrator((x0, v0), controls, dt)\n",
        "        elif system_type == \"van_der_pol\":\n",
        "            traj = simulate_van_der_pol((x0, v0), controls, dt)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown system type: {system_type}\")\n",
        "        \n",
        "        trajectories.append(traj)\n",
        "    \n",
        "    return trajectories\n",
        "\n",
        "def plot_comparison_by_system(system_type, initial_states, optimal_trajectories, model_trajectories, dt):\n",
        "    \"\"\"\n",
        "    Plot comparison between optimal and model trajectories specific to a system type.\n",
        "    \n",
        "    Args:\n",
        "        system_type: Either \"double_integrator\" or \"van_der_pol\"\n",
        "        initial_states: List of (position, velocity) tuples\n",
        "        optimal_trajectories: List of optimal trajectory dictionaries\n",
        "        model_trajectories: List of model trajectory dictionaries\n",
        "        dt: Time step size\n",
        "    \"\"\"\n",
        "    # Configure system-specific parameters\n",
        "    if system_type == \"double_integrator\":\n",
        "        system_name = \"Double Integrator\"\n",
        "        control_bounds = (-3, 3)\n",
        "        state_bounds = (-1, 1)\n",
        "        optimal_name = \"LQR\"\n",
        "    elif system_type == \"van_der_pol\":\n",
        "        system_name = \"Van der Pol Oscillator\"\n",
        "        control_bounds = (-5, 5)\n",
        "        state_bounds = (-2, 2)\n",
        "        optimal_name = \"Optimal\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown system type: {system_type}\")\n",
        "    \n",
        "    # Create plots\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(14, 12))\n",
        "    \n",
        "    # Plot settings\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(initial_states)))\n",
        "    \n",
        "    for i, ((x0, v0), opt_traj, model_traj, color) in enumerate(zip(\n",
        "        initial_states, optimal_trajectories, model_trajectories, colors)):\n",
        "        \n",
        "        # Position plot\n",
        "        axs[0].plot(opt_traj['times'], opt_traj['positions'], 'b-', label=optimal_name)\n",
        "        axs[0].plot(model_traj['times'], model_traj['positions'], 'r--', marker='.', label='Model')\n",
        "        axs[0].axhline(y=state_bounds[0], color='r', linestyle=':')\n",
        "        axs[0].axhline(y=state_bounds[1], color='r', linestyle=':')\n",
        "        axs[0].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].set_title(f'{system_name} Position Trajectory')\n",
        "        axs[0].set_ylabel('Position')\n",
        "        axs[0].legend()\n",
        "        \n",
        "        # Velocity plot\n",
        "        axs[1].plot(opt_traj['times'], opt_traj['velocities'], 'g-', label=optimal_name)\n",
        "        axs[1].plot(model_traj['times'], model_traj['velocities'], 'r--', marker='.', label='Model')\n",
        "        axs[1].axhline(y=state_bounds[0], color='r', linestyle=':')\n",
        "        axs[1].axhline(y=state_bounds[1], color='r', linestyle=':')\n",
        "        axs[1].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].set_ylabel('Velocity')\n",
        "        axs[1].legend()\n",
        "        \n",
        "        # Control plot\n",
        "        axs[2].step(opt_traj['times'], opt_traj['controls'], 'b-', where='post', label=optimal_name)\n",
        "        axs[2].step(model_traj['times'], model_traj['controls'], 'r--', marker='.', where='post', label='Model')\n",
        "        axs[2].axhline(y=control_bounds[0], color='r', linestyle=':')\n",
        "        axs[2].axhline(y=control_bounds[1], color='r', linestyle=':')\n",
        "        axs[2].grid(True)\n",
        "        axs[2].set_ylabel('Control Input')\n",
        "        axs[2].set_xlabel('Time (s)')\n",
        "        axs[2].legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(hspace=0.3)\n",
        "        plt.show()\n",
        "        \n",
        "        # Phase portrait\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        \n",
        "        # Draw state bounds as a rectangle\n",
        "        plt.plot([x[0] for x in initial_states], [x[1] for x in initial_states], 'go', label='Initial States')\n",
        "        plt.plot(opt_traj['positions'], opt_traj['velocities'], 'b-', label=optimal_name)\n",
        "        plt.plot(model_traj['positions'], model_traj['velocities'], 'r--', marker='.', label='Model')\n",
        "        \n",
        "        # Mark origin with a star\n",
        "        plt.plot(0, 0, '*', color='k', markersize=12, label='Target')\n",
        "        \n",
        "        plt.axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        plt.axvline(x=0, color='k', linestyle='-', alpha=0.5)\n",
        "        plt.grid(True)\n",
        "        plt.title(f'{system_name} Phase Portrait')\n",
        "        plt.xlabel('Position')\n",
        "        plt.ylabel('Velocity')\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "\n",
        "def evaluate_model_on_system(model, tokenizer, system_type, num_test_cases=5, lora_path=None):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on a specific system.\n",
        "    \n",
        "    Args:\n",
        "        model: The trained model\n",
        "        tokenizer: The tokenizer\n",
        "        system_type: Either \"double_integrator\" or \"van_der_pol\"\n",
        "        num_test_cases: Number of random test cases to generate\n",
        "        lora_path: Path to the LoRA weights (optional)\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (optimal_trajectories, model_trajectories)\n",
        "    \"\"\"\n",
        "    # Set appropriate random bounds based on system type\n",
        "    if system_type == \"double_integrator\":\n",
        "        pos_bounds = (-0.8, 0.8)\n",
        "        vel_bounds = (-0.8, 0.8)\n",
        "    elif system_type == \"van_der_pol\":\n",
        "        pos_bounds = (-1.5, 1.5)\n",
        "        vel_bounds = (-1.5, 1.5)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown system type: {system_type}\")\n",
        "    \n",
        "    # Generate random initial conditions\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    test_positions = np.random.uniform(pos_bounds[0], pos_bounds[1], num_test_cases)\n",
        "    test_velocities = np.random.uniform(vel_bounds[0], vel_bounds[1], num_test_cases)\n",
        "    initial_states = list(zip(test_positions, test_velocities))\n",
        "    \n",
        "    # Generate optimal solutions based on system type\n",
        "    if system_type == \"double_integrator\":\n",
        "        optimal_controls = [solve_double_integrator(x0, v0, dt, steps) for x0, v0 in initial_states]\n",
        "    else:  # van_der_pol\n",
        "        optimal_controls = [solve_van_der_pol(x0, v0, 1.0, dt, steps) for x0, v0 in initial_states]\n",
        "    \n",
        "    # Generate model solutions\n",
        "    model_controls = generate_model_controls_for_system(\n",
        "        model, tokenizer, system_type, test_positions, test_velocities, dt, steps, lora_path\n",
        "    )\n",
        "    \n",
        "    # Simulate both solutions\n",
        "    optimal_trajectories = simulate_trajectories_by_system(system_type, initial_states, optimal_controls, dt)\n",
        "    model_trajectories = simulate_trajectories_by_system(system_type, initial_states, model_controls, dt)\n",
        "    \n",
        "    # Calculate evaluation metrics\n",
        "    optimal_final_errors = [traj['final_error'] for traj in optimal_trajectories]\n",
        "    model_final_errors = [traj['final_error'] for traj in model_trajectories]\n",
        "    \n",
        "    print(f\"\\n=== Evaluation Results for {system_type.upper()} ===\")\n",
        "    print(f\"Average Optimal final error: {np.mean(optimal_final_errors):.6f}\")\n",
        "    print(f\"Average Model final error: {np.mean(model_final_errors):.6f}\")\n",
        "    \n",
        "    # Plot comparison\n",
        "    plot_comparison_by_system(system_type, initial_states, optimal_trajectories, model_trajectories, dt)\n",
        "    \n",
        "    return optimal_trajectories, model_trajectories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Inference Pipeline\n",
        "\n",
        "Now let's create a comprehensive inference pipeline to evaluate our trained model on both the double integrator and Van der Pol systems. This will allow us to:\n",
        "\n",
        "1. Test the model with different initial conditions\n",
        "2. Compare model performance with optimal control solutions\n",
        "3. Visualize the results with detailed plots\n",
        "4. Provide an interactive interface for experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for inference\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from scipy.integrate import solve_ivp\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive, FloatSlider, Dropdown, Output, VBox, HBox, Button, Label\n",
        "\n",
        "# Define helper functions for inference\n",
        "def extract_controls_from_response(response_text):\n",
        "    \"\"\"Extract control values from model response using regex.\"\"\"\n",
        "    # Extract control sequence\n",
        "    control_match = re.search(rf\"{solution_start}(.*?){solution_end}\", response_text, re.DOTALL)\n",
        "    \n",
        "    if control_match is None:\n",
        "        print(\"ERROR: Could not extract control values from response\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        # Parse control values\n",
        "        control_text = control_match.group(1).strip()\n",
        "        control_values = [float(x.strip()) for x in control_text.split(',')]\n",
        "        return control_values\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR parsing control values: {e}\")\n",
        "        return None\n",
        "    \n",
        "def extract_reasoning_from_response(response_text):\n",
        "    \"\"\"Extract reasoning text from model response.\"\"\"\n",
        "    # Extract reasoning sequence\n",
        "    reasoning_match = re.search(rf\"{reasoning_start}(.*?){reasoning_end}\", response_text, re.DOTALL)\n",
        "    \n",
        "    if reasoning_match is None:\n",
        "        print(\"WARNING: Could not extract reasoning from response\")\n",
        "        return None\n",
        "    \n",
        "    return reasoning_match.group(1).strip()\n",
        "\n",
        "def simulate_by_system_type(system_type, initial_state, control_sequence, dt):\n",
        "    \"\"\"Simulate system based on system type.\"\"\"\n",
        "    if system_type == \"double_integrator\":\n",
        "        x0, v0 = initial_state\n",
        "        # Simulate trajectory\n",
        "        x, v = x0, v0\n",
        "        positions = [x]\n",
        "        velocities = [v]\n",
        "        times = [0]\n",
        "        \n",
        "        for i, u in enumerate(control_sequence):\n",
        "            # Bound control within limits for double integrator\n",
        "            u_clamped = max(-3.0, min(3.0, u))\n",
        "            \n",
        "            # Apply simple Euler integration for double integrator\n",
        "            v = v + u_clamped * dt\n",
        "            x = x + v * dt\n",
        "            \n",
        "            # Bound states if needed\n",
        "            x = max(-1.0, min(1.0, x))\n",
        "            v = max(-1.0, min(1.0, v))\n",
        "            \n",
        "            positions.append(x)\n",
        "            velocities.append(v)\n",
        "            times.append((i+1) * dt)\n",
        "        \n",
        "        return {\n",
        "            'times': times,\n",
        "            'positions': positions,\n",
        "            'velocities': velocities,\n",
        "            'controls': control_sequence,\n",
        "            'final_error': (positions[-1]**2 + velocities[-1]**2)**0.5\n",
        "        }\n",
        "    elif system_type == \"van_der_pol\":\n",
        "        x0, v0 = initial_state\n",
        "        mu = 1.0  # Standard value for Van der Pol\n",
        "        \n",
        "        # Define Van der Pol dynamics with control\n",
        "        def vdp_dynamics(t, state, u):\n",
        "            x, v = state\n",
        "            dxdt = v\n",
        "            dvdt = mu * (1 - x**2) * v - x + u\n",
        "            return [dxdt, dvdt]\n",
        "        \n",
        "        # Simulate trajectory\n",
        "        x, v = x0, v0\n",
        "        positions = [x]\n",
        "        velocities = [v]\n",
        "        times = [0]\n",
        "        \n",
        "        for i, u in enumerate(control_sequence):\n",
        "            # Bound control within limits for Van der Pol\n",
        "            u_clamped = max(-5.0, min(5.0, u))\n",
        "            \n",
        "            # Simulate one step with Runge-Kutta integration\n",
        "            sol = solve_ivp(\n",
        "                lambda t, y: vdp_dynamics(t, y, u_clamped),\n",
        "                [0, dt], [x, v], method='RK45', t_eval=[dt]\n",
        "            )\n",
        "            \n",
        "            x, v = sol.y[:, -1].tolist()\n",
        "            \n",
        "            # Bound states if needed\n",
        "            x = max(-2.0, min(2.0, x))\n",
        "            v = max(-2.0, min(2.0, v))\n",
        "            \n",
        "            positions.append(x)\n",
        "            velocities.append(v)\n",
        "            times.append((i+1) * dt)\n",
        "    \n",
        "        return {\n",
        "            'times': times,\n",
        "            'positions': positions,\n",
        "            'velocities': velocities,\n",
        "            'controls': control_sequence,\n",
        "            'final_error': (positions[-1]**2 + velocities[-1]**2)**0.5\n",
        "        }\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown system type: {system_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_system_comparison(system_type, initial_state, optimal_trajectory, model_trajectory):\n",
        "    \"\"\"\n",
        "    Plot comparison between optimal and model trajectories for a single initial state.\n",
        "    \"\"\"\n",
        "    # Configure system-specific parameters\n",
        "    if system_type == \"double_integrator\":\n",
        "        system_name = \"Double Integrator\"\n",
        "        control_bounds = (-3, 3)\n",
        "        state_bounds = (-1, 1)\n",
        "        optimal_name = \"LQR\"\n",
        "    elif system_type == \"van_der_pol\":\n",
        "        system_name = \"Van der Pol Oscillator\"\n",
        "        control_bounds = (-5, 5)\n",
        "        state_bounds = (-2, 2)\n",
        "        optimal_name = \"Optimal\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown system type: {system_type}\")\n",
        "    \n",
        "    x0, v0 = initial_state\n",
        "    dt = optimal_trajectory['times'][1] - optimal_trajectory['times'][0]\n",
        "    \n",
        "    # Create figure with 3 subplots\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(12, 10))\n",
        "    \n",
        "    # Position plot\n",
        "    axs[0].plot(optimal_trajectory['times'], optimal_trajectory['positions'], 'b-', label=optimal_name, linewidth=2)\n",
        "    axs[0].plot(model_trajectory['times'], model_trajectory['positions'], 'r--', marker='.', label='Model', linewidth=2)\n",
        "    axs[0].axhline(y=state_bounds[0], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[0].axhline(y=state_bounds[1], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[0].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "    axs[0].grid(True)\n",
        "    axs[0].set_title(f'{system_name} Trajectory - Initial State: ({x0:.2f}, {v0:.2f})', fontsize=14)\n",
        "    axs[0].set_ylabel('Position', fontsize=12)\n",
        "    axs[0].legend(fontsize=12)\n",
        "    \n",
        "    # Velocity plot\n",
        "    axs[1].plot(optimal_trajectory['times'], optimal_trajectory['velocities'], 'b-', label=optimal_name, linewidth=2)\n",
        "    axs[1].plot(model_trajectory['times'], model_trajectory['velocities'], 'r--', marker='.', label='Model', linewidth=2)\n",
        "    axs[1].axhline(y=state_bounds[0], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[1].axhline(y=state_bounds[1], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[1].axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "    axs[1].grid(True)\n",
        "    axs[1].set_ylabel('Velocity', fontsize=12)\n",
        "    axs[1].legend(fontsize=12)\n",
        "    \n",
        "    # Control plot\n",
        "    time_points = [i*dt for i in range(len(optimal_trajectory['controls']))]\n",
        "    axs[2].step(time_points, optimal_trajectory['controls'], 'b-', where='post', label=optimal_name, linewidth=2)\n",
        "    axs[2].step(time_points, model_trajectory['controls'], 'r--', marker='.', where='post', label='Model', linewidth=2)\n",
        "    axs[2].axhline(y=control_bounds[0], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[2].axhline(y=control_bounds[1], color='r', linestyle=':', alpha=0.7)\n",
        "    axs[2].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "    axs[2].grid(True)\n",
        "    axs[2].set_ylabel('Control Input', fontsize=12)\n",
        "    axs[2].set_xlabel('Time (seconds)', fontsize=12)\n",
        "    axs[2].legend(fontsize=12)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Phase portrait (separate figure)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    # Draw state bounds as dashed lines\n",
        "    plt.axhline(y=state_bounds[0], color='r', linestyle=':', alpha=0.7)\n",
        "    plt.axhline(y=state_bounds[1], color='r', linestyle=':', alpha=0.7)\n",
        "    plt.axvline(x=state_bounds[0], color='r', linestyle=':', alpha=0.7)\n",
        "    plt.axvline(x=state_bounds[1], color='r', linestyle=':', alpha=0.7)\n",
        "    \n",
        "    # Plot phase trajectories\n",
        "    plt.plot(x0, v0, 'go', markersize=10, label='Initial State')\n",
        "    plt.plot(optimal_trajectory['positions'], optimal_trajectory['velocities'], 'b-', label=optimal_name, linewidth=2)\n",
        "    plt.plot(model_trajectory['positions'], model_trajectory['velocities'], 'r--', marker='.', label='Model', linewidth=2)\n",
        "    \n",
        "    # Mark origin with a star\n",
        "    plt.plot(0, 0, '*', color='k', markersize=15, label='Target')\n",
        "    \n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.5)\n",
        "    plt.grid(True)\n",
        "    plt.title(f'{system_name} Phase Portrait', fontsize=14)\n",
        "    plt.xlabel('Position', fontsize=12)\n",
        "    plt.ylabel('Velocity', fontsize=12)\n",
        "    plt.legend(fontsize=12, loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    # Print performance summary\n",
        "    opt_final_x = optimal_trajectory['positions'][-1]\n",
        "    opt_final_v = optimal_trajectory['velocities'][-1]\n",
        "    model_final_x = model_trajectory['positions'][-1] \n",
        "    model_final_v = model_trajectory['velocities'][-1];\n",
        "    \n",
        "    print(f\"\\n=== Performance Summary for {system_name} ===\")\n",
        "    print(f\"Initial state: position = {x0:.4f}, velocity = {v0:.4f}\")\n",
        "    print(f\"Final state ({optimal_name}): position = {opt_final_x:.6f}, velocity = {opt_final_v:.6f}\")\n",
        "    print(f\"Final state (Model): position = {model_final_x:.6f}, velocity = {model_final_v:.6f}\")\n",
        "    print(f\"Final error ({optimal_name}): {optimal_trajectory['final_error']:.6f}\")\n",
        "    print(f\"Final error (Model): {model_trajectory['final_error']:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model_on_custom_state(model, tokenizer, system_type, x0, v0, dt=0.1, steps=50, lora_path=\"di_vdp_control_lora\"):\n",
        "    \"\"\"Test the model on a custom initial state.\"\"\"\n",
        "    print(f\"Testing {system_type.replace('_', ' ').title()} with initial state: position = {x0:.2f}, velocity = {v0:.2f}\")\n",
        "    \n",
        "    # Load LoRA weights\n",
        "    try:\n",
        "        lora_request = model.load_lora(lora_path)\n",
        "        print(f\"Loaded LoRA weights from {lora_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to load LoRA weights: {e}\")\n",
        "        lora_request = None\n",
        "    \n",
        "    # Get system-specific prompt\n",
        "    system_prompt = get_system_prompt(dt, steps, system_type)\n",
        "    total_time = dt * steps\n",
        "    \n",
        "    # Construct user prompt\n",
        "    if system_type == 'double_integrator':\n",
        "        user_prompt = f\"Control a double integrator system with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time:.2f} seconds using {steps} steps. Ensure all states remain within [-1,1] and controls within [-3,3].\"\n",
        "    else:  # van_der_pol\n",
        "        user_prompt = f\"Control a Van der Pol oscillator system (μ=1) with initial state [position={x0:.2f}, velocity={v0:.2f}] to reach the origin (0,0) in {total_time:.2f} seconds using {steps} steps. Ensure all states remain within [-2,2] and controls within [-5,5].\"\n",
        "    \n",
        "    # Format chat message\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "    \n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False,\n",
        "    )\n",
        "    \n",
        "    # Run inference\n",
        "    from vllm import SamplingParams\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    \n",
        "    print(\"Generating model solution...\")\n",
        "    model_output = model.fast_generate(\n",
        "        text,\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=lora_request,\n",
        "    )[0].outputs[0].text\n",
        "    \n",
        "    # Extract reasoning and controls\n",
        "    reasoning = extract_reasoning_from_response(model_output)\n",
        "    controls = extract_controls_from_response(model_output)\n",
        "    \n",
        "    if controls is None:\n",
        "        print(\"Failed to extract controls from model output.\")\n",
        "        print(\"Model output:\", model_output)\n",
        "        return None\n",
        "    \n",
        "    # Generate optimal solution\n",
        "    if system_type == 'double_integrator':\n",
        "        optimal_controls = solve_double_integrator(x0, v0, dt, steps)\n",
        "    else:  # van_der_pol\n",
        "        optimal_controls = solve_van_der_pol(x0, v0, 1.0, dt, steps)\n",
        "    \n",
        "    # Simulate both trajectories\n",
        "    optimal_traj = simulate_by_system_type(system_type, (x0, v0), optimal_controls, dt)\n",
        "    model_traj = simulate_by_system_type(system_type, (x0, v0), controls, dt)\n",
        "    \n",
        "    # Plot comparison\n",
        "    plot_system_comparison(system_type, (x0, v0), optimal_traj, model_traj)\n",
        "    \n",
        "    # If reasoning is available, display it\n",
        "    if reasoning:\n",
        "        print(\"\\n=== Model's Reasoning ===\")\n",
        "        print(reasoning)\n",
        "    \n",
        "    # Return results for further analysis if needed\n",
        "    return {\n",
        "        \"system_type\": system_type,\n",
        "        \"initial_state\": (x0, v0),\n",
        "        \"model_controls\": controls,\n",
        "        \"optimal_controls\": optimal_controls,\n",
        "        \"model_trajectory\": model_traj,\n",
        "        \"optimal_trajectory\": optimal_traj,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"model_output\": model_output\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_interactive_tester():\n",
        "    \"\"\"Create an interactive widget for testing the model.\"\"\"\n",
        "    system_type = widgets.Dropdown(\n",
        "        options=[('Double Integrator', 'double_integrator'), ('Van der Pol', 'van_der_pol')],\n",
        "        value='double_integrator',\n",
        "        description='System:',\n",
        "        disabled=False,\n",
        "    )\n",
        "    \n",
        "    x0_slider = widgets.FloatSlider(\n",
        "        value=0.5,\n",
        "        min=-1.5,\n",
        "        max=1.5,\n",
        "        step=0.1,\n",
        "        description='Position:',\n",
        "        disabled=False,\n",
        "        continuous_update=False,\n",
        "    )\n",
        "    \n",
        "    v0_slider = widgets.FloatSlider(\n",
        "        value=-0.3,\n",
        "        min=-1.5,\n",
        "        max=1.5,\n",
        "        step=0.1,\n",
        "        description='Velocity:',\n",
        "        disabled=False,\n",
        "        continuous_update=False,\n",
        "    )\n",
        "    \n",
        "    run_button = widgets.Button(\n",
        "        description='Run Test',\n",
        "        disabled=False,\n",
        "        button_style='success',\n",
        "        tooltip='Click to run test',\n",
        "        icon='check'\n",
        "    )\n",
        "    \n",
        "    output = widgets.Output()\n",
        "    \n",
        "    # Update slider ranges based on system type\n",
        "    def update_sliders(change):\n",
        "        if change['new'] == 'double_integrator':\n",
        "            x0_slider.min = -0.9\n",
        "            x0_slider.max = 0.9\n",
        "            v0_slider.min = -0.9\n",
        "            v0_slider.max = 0.9\n",
        "        else:  # van_der_pol\n",
        "            x0_slider.min = -1.8\n",
        "            x0_slider.max = 1.8\n",
        "            v0_slider.min = -1.8\n",
        "            v0_slider.max = 1.8\n",
        "    \n",
        "    system_type.observe(update_sliders, names='value')\n",
        "    \n",
        "    # Run the test when button is clicked\n",
        "    def on_button_click(b):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            test_model_on_custom_state(\n",
        "                model, tokenizer,\n",
        "                system_type.value, \n",
        "                x0_slider.value, \n",
        "                v0_slider.value\n",
        "            )\n",
        "    \n",
        "    run_button.on_click(on_button_click)\n",
        "    \n",
        "    # Put everything together\n",
        "    ui = widgets.VBox([\n",
        "        widgets.HBox([system_type]),\n",
        "        widgets.HBox([x0_slider]),\n",
        "        widgets.HBox([v0_slider]),\n",
        "        widgets.HBox([run_button]),\n",
        "        output\n",
        "    ])\n",
        "    \n",
        "    return ui\n",
        "\n",
        "# Test the model on specific examples\n",
        "print(\"=== Testing Double Integrator System ===\")\n",
        "di_result = test_model_on_custom_state(\n",
        "    model, tokenizer,\n",
        "    'double_integrator',\n",
        "    0.5, -0.3\n",
        ")\n",
        "\n",
        "print(\"\\n=== Testing Van der Pol System ===\")\n",
        "vdp_result = test_model_on_custom_state(\n",
        "    model, tokenizer,\n",
        "    'van_der_pol',\n",
        "    1.0, 0.0\n",
        ")\n",
        "\n",
        "# Create and display the interactive interface\n",
        "print(\"\\nInteractive Testing Interface:\")\n",
        "interactive_tester = create_interactive_tester()\n",
        "display(interactive_tester)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Predictive Control (MPC) Testing Pipeline\n",
        "\n",
        "In this section, we'll implement and test the Model Predictive Control (MPC) approach for trained models. \n",
        "\n",
        "**What is MPC?**\n",
        "\n",
        "Model Predictive Control (MPC) is a control strategy that:\n",
        "1. Predicts system behavior over a finite future horizon\n",
        "2. Computes optimal controls for the entire horizon\n",
        "3. Applies only the first control input\n",
        "4. Shifts the horizon and repeats the process at each time step\n",
        "\n",
        "This approach allows for feedback at each time step, making the system more robust to prediction errors and disturbances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import MPC testing pipeline utilities\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Make sure the utility modules are in the path\n",
        "current_dir = os.path.abspath('.')\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.append(current_dir)\n",
        "\n",
        "# Import MPC utilities from the mpc_testing_pipeline module\n",
        "from mpc_testing_pipeline import (\n",
        "    generate_model_controls_mpc,\n",
        "    test_mpc_on_system,\n",
        "    evaluate_mpc_batch,\n",
        "    plot_mpc_comparison,\n",
        "    plot_multi_mpc_comparison,\n",
        "    create_mpc_interactive_tester\n",
        ")\n",
        "\n",
        "print(\"MPC pipeline utilities imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MPC for Double Integrator\n",
        "\n",
        "Let's test the MPC approach on the double integrator system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single test case for Double Integrator system\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MPC TEST FOR DOUBLE INTEGRATOR SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "di_mpc_result = test_mpc_on_system(\n",
        "    model, tokenizer, 'double_integrator',\n",
        "    0.5, -0.3,  # Initial position and velocity\n",
        "    0.1, 50, 10,  # dt, steps, prediction_horizon\n",
        "    lora_path=\"di_vdp_control_lora\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MPC for Van der Pol Oscillator\n",
        "\n",
        "Now let's test the MPC approach on the Van der Pol oscillator system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single test case for Van der Pol oscillator system\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MPC TEST FOR VAN DER POL OSCILLATOR SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "vdp_mpc_result = test_mpc_on_system(\n",
        "    model, tokenizer, 'van_der_pol',\n",
        "    1.0, 0.0,  # Initial position and velocity\n",
        "    0.1, 50, 10,  # dt, steps, prediction_horizon\n",
        "    lora_path=\"di_vdp_control_lora\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch MPC Testing\n",
        "\n",
        "Next, let's run MPC on a batch of initial states and compare with optimal solutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Double Integrator batch test\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BATCH MPC TEST FOR DOUBLE INTEGRATOR SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "di_test_cases = [\n",
        "    (0.5, 0.0),    # Position offset only\n",
        "    (0.0, 0.5),    # Velocity offset only\n",
        "    (0.5, -0.5),   # Mixed initial condition\n",
        "    (-0.7, 0.3),   # Another mixed case\n",
        "]\n",
        "\n",
        "di_optimal_trajectories, di_mpc_trajectories = evaluate_mpc_batch(\n",
        "    model, tokenizer, 'double_integrator', di_test_cases, \n",
        "    dt=0.1, steps=50, prediction_horizon=10, \n",
        "    lora_path=\"di_vdp_control_lora\"\n",
        ")\n",
        "\n",
        "# Plot multiple trajectories for double integrator\n",
        "plot_multi_mpc_comparison(\n",
        "    'double_integrator', di_test_cases, \n",
        "    di_optimal_trajectories, di_mpc_trajectories, dt=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Van der Pol batch test\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BATCH MPC TEST FOR VAN DER POL OSCILLATOR SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "vdp_test_cases = [\n",
        "    (1.0, 0.0),    # Position offset only\n",
        "    (0.0, 1.0),    # Velocity offset only\n",
        "    (1.0, -1.0),   # Mixed initial condition\n",
        "    (-0.5, 0.5),   # Another mixed case\n",
        "]\n",
        "\n",
        "vdp_optimal_trajectories, vdp_mpc_trajectories = evaluate_mpc_batch(\n",
        "    model, tokenizer, 'van_der_pol', vdp_test_cases, \n",
        "    dt=0.1, steps=50, prediction_horizon=10, \n",
        "    lora_path=\"di_vdp_control_lora\"\n",
        ")\n",
        "\n",
        "# Plot multiple trajectories for Van der Pol\n",
        "plot_multi_mpc_comparison(\n",
        "    'van_der_pol', vdp_test_cases, \n",
        "    vdp_optimal_trajectories, vdp_mpc_trajectories, dt=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interactive MPC Tester\n",
        "\n",
        "Let's create an interactive interface to test the MPC approach with different parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and display the interactive MPC testing interface\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERACTIVE MPC TESTING INTERFACE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "interactive_mpc_tester = create_mpc_interactive_tester(model, tokenizer)\n",
        "display(interactive_mpc_tester)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding MPC vs Full-Horizon Prediction\n",
        "\n",
        "Let's discuss the advantages and disadvantages of the MPC approach compared to full-horizon prediction.\n",
        "\n",
        "#### Advantages of MPC:\n",
        "- **Feedback control**: Incorporates feedback at each time step, making it more robust to modeling errors and disturbances\n",
        "- **Adaptive control**: Can adjust to changing conditions or modeling errors during execution\n",
        "- **Reduced prediction horizon**: Only needs to make accurate predictions over a shorter horizon\n",
        "- **Practical for real-world systems**: Better matches how control would be applied in actual systems\n",
        "\n",
        "#### Disadvantages of MPC:\n",
        "- **Computational cost**: Requires recomputing the control sequence at each time step\n",
        "- **May miss global optimality**: Short-horizon predictions might not capture the globally optimal solution\n",
        "- **Increased latency**: In real-time applications, computation time becomes a factor\n",
        "\n",
        "#### What We Observed:\n",
        "- MPC generally produces smoother trajectories with smaller control inputs\n",
        "- The final state error is typically slightly higher with MPC than with full-horizon optimal control\n",
        "- For highly nonlinear systems like the Van der Pol oscillator, MPC shows more significant advantages due to its ability to adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "unsloth_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "051022abbc21456f89ac56364f827a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5218777759ce48f79834aefc8e9a9320",
            "placeholder": "​",
            "style": "IPY_MODEL_a3d222daa599414b9d31a4bc9fed9c2c",
            "value": " 23/23 [00:30&lt;00:00,  1.34s/it]"
          }
        },
        "11f935907b9e469e8167c7669764ae4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccb880d39da499db25b740262916944",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a51e7c117924754acddc2d2750d3ac0",
            "value": 1
          }
        },
        "12630f33d40541b6bcb63b86be4b340c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13824ab11776462199dc487e3dd9f33f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ac50082b6744a2b70b2bf785b5299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc24ae1ea2e498f8ce1b7afb016f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f99af7066114110bc28d113ee32072d",
              "IPY_MODEL_fa6ed0d48fd04726b9a6bc92b5ec3708",
              "IPY_MODEL_2aee8e461c3144c382532649cc067f61"
            ],
            "layout": "IPY_MODEL_41ff4ea73396420f952b396560249270"
          }
        },
        "207997f1fc1e4ab68a0de0b880bfae55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec663b7c3d774d3cb976e6d1fa30a999",
            "placeholder": "​",
            "style": "IPY_MODEL_f22b1d60ae234506b37cb11aa5c5de51",
            "value": "Capturing CUDA graph shapes: 100%"
          }
        },
        "23111afc4a914829a3d24314ca66f33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cdb5f4454d4cb8af8a055c536912e3",
            "placeholder": "​",
            "style": "IPY_MODEL_7e145207293e420f8a5be01a85e5861b",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:49&lt;00:00, 25.80s/it]\n"
          }
        },
        "2aee8e461c3144c382532649cc067f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13824ab11776462199dc487e3dd9f33f",
            "placeholder": "​",
            "style": "IPY_MODEL_e82075463a424e5e8dc62dee8ff2686e",
            "value": " 1/1 [00:41&lt;00:00, 41.39s/it, est. speed input: 0.24 toks/s, output: 24.74 toks/s]"
          }
        },
        "2f8779bce6e249c2846639cf3431cd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df3ea2ea5de243fa8b5bdaab82f7b7c3",
              "IPY_MODEL_36323e9f8ce040c2b9ba0d67f2d88d1a",
              "IPY_MODEL_23111afc4a914829a3d24314ca66f33d"
            ],
            "layout": "IPY_MODEL_edacc2c8ff9e4eaf886e5b49e21b7e11"
          }
        },
        "326713cc0b7c478291652c9324127149": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36323e9f8ce040c2b9ba0d67f2d88d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326713cc0b7c478291652c9324127149",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_802bf28a6a144a049e9b3f3af234f88c",
            "value": 2
          }
        },
        "38cdb5f4454d4cb8af8a055c536912e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f99af7066114110bc28d113ee32072d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74afa76a26f245519932d02b8042e5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a4ebf0f16d499a917034f45ec7050f",
            "value": "Processed prompts: 100%"
          }
        },
        "41ff4ea73396420f952b396560249270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "44e07fc58e3e44fb9223e7cec91847d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "493acc3b55f441219300802810be7004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e5ebf7203b2467abdd0b871d6b72f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2fd49b789d3418292c1bcd1439e2e84",
              "IPY_MODEL_11f935907b9e469e8167c7669764ae4c",
              "IPY_MODEL_81d28dde142049519cd27f87c68c92fa"
            ],
            "layout": "IPY_MODEL_c73269d5f6134c539249d28e7809a003"
          }
        },
        "5218777759ce48f79834aefc8e9a9320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f2c1ecbeeb4b53af6aa3264008e6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_207997f1fc1e4ab68a0de0b880bfae55",
              "IPY_MODEL_5fb90177a4fa480c8c80474be786cbae",
              "IPY_MODEL_051022abbc21456f89ac56364f827a73"
            ],
            "layout": "IPY_MODEL_db1133419f184e459153347ff2653c17"
          }
        },
        "5e32cde8bae04944acb9b81d72083d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c310891371442e7ace9bb2cb427f157",
              "IPY_MODEL_e79bc585dceb4cf78d07b006517de7da",
              "IPY_MODEL_acab127a93654604ae5c7b2b3241e262"
            ],
            "layout": "IPY_MODEL_12630f33d40541b6bcb63b86be4b340c"
          }
        },
        "5fb90177a4fa480c8c80474be786cbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5e3fe437024acc89e4caf71447a558",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d29a6452c0cd49b3932206e8aa0b4c1c",
            "value": 23
          }
        },
        "6e482123e4aa4a3195a5b5a5d4289a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74afa76a26f245519932d02b8042e5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e145207293e420f8a5be01a85e5861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "802bf28a6a144a049e9b3f3af234f88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81d28dde142049519cd27f87c68c92fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85cf8527998d49c18d89f8d82271c534",
            "placeholder": "​",
            "style": "IPY_MODEL_fe778d62c7f34683810ad613114ae4c1",
            "value": " 1/1 [01:33&lt;00:00, 93.24s/it, est. speed input: 0.62 toks/s, output: 21.35 toks/s]"
          }
        },
        "85cf8527998d49c18d89f8d82271c534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4ffe2fa4e04945b816752992077a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a5e3fe437024acc89e4caf71447a558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c310891371442e7ace9bb2cb427f157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd27e26dd6c4f5a80d4ee674e3a1941",
            "placeholder": "​",
            "style": "IPY_MODEL_13ac50082b6744a2b70b2bf785b5299c",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "9a51e7c117924754acddc2d2750d3ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3d222daa599414b9d31a4bc9fed9c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acab127a93654604ae5c7b2b3241e262": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d796eb8672674433ba1d6378d7140623",
            "placeholder": "​",
            "style": "IPY_MODEL_44e07fc58e3e44fb9223e7cec91847d6",
            "value": " 59/59 [00:01&lt;00:00, 47.67 examples/s]"
          }
        },
        "aee30c91cc634ee2b8dd9ed9238c8377": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f877c8eb5c4f78821d40f27a867f09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73269d5f6134c539249d28e7809a003": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c9a4ebf0f16d499a917034f45ec7050f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d29a6452c0cd49b3932206e8aa0b4c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d796eb8672674433ba1d6378d7140623": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab2cfcb9e53486582d98dd35c56654a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db1133419f184e459153347ff2653c17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd27e26dd6c4f5a80d4ee674e3a1941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3ea2ea5de243fa8b5bdaab82f7b7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e1e56e67b240f1802ce888c62c9860",
            "placeholder": "​",
            "style": "IPY_MODEL_dab2cfcb9e53486582d98dd35c56654a",
            "value": ""
          }
        },
        "e2bb8a2af8ba451fa113d77556080d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e1e56e67b240f1802ce888c62c9860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79bc585dceb4cf78d07b006517de7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bb8a2af8ba451fa113d77556080d3e",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a4ffe2fa4e04945b816752992077a79",
            "value": 59
          }
        },
        "e82075463a424e5e8dc62dee8ff2686e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec663b7c3d774d3cb976e6d1fa30a999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccb880d39da499db25b740262916944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edacc2c8ff9e4eaf886e5b49e21b7e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22b1d60ae234506b37cb11aa5c5de51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2fd49b789d3418292c1bcd1439e2e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f877c8eb5c4f78821d40f27a867f09",
            "placeholder": "​",
            "style": "IPY_MODEL_493acc3b55f441219300802810be7004",
            "value": "Processed prompts: 100%"
          }
        },
        "fa6ed0d48fd04726b9a6bc92b5ec3708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee30c91cc634ee2b8dd9ed9238c8377",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e482123e4aa4a3195a5b5a5d4289a20",
            "value": 1
          }
        },
        "fe778d62c7f34683810ad613114ae4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
