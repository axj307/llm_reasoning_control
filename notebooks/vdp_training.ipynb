{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Van der Pol Oscillator Training Notebook\n",
    "\n",
    "This notebook provides a clean interface for training and evaluating models on the Van der Pol oscillator system.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup & Data Generation\n",
    "2. SFT Training (Optional)\n",
    "3. GRPO Training (Optional) \n",
    "4. SFT + GRPO Training (Combined)\n",
    "5. Model Evaluation\n",
    "6. Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from config import ALL_CONFIG, AVAILABLE_SYSTEMS\n",
    "from core.model_manager import UniversalModelManager\n",
    "from core.data_pipeline import UniversalDataGenerator\n",
    "from training.sft_training import train_sft_model, setup_universal_chat_template, save_sft_model\n",
    "from training.grpo_training import train_grpo_model, save_grpo_model\n",
    "from evaluation.inference import run_batch_inference\n",
    "from evaluation.metrics import compute_batch_metrics\n",
    "from evaluation.visualization import plot_comparison, plot_metrics_comparison\n",
    "from environments import get_system\n",
    "from data_utils import load_train_eval_datasets, list_available_datasets\n",
    "from gpu_utils import auto_gpu_config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ All modules loaded successfully!\")\n",
    "print(f\"Available systems: {AVAILABLE_SYSTEMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SYSTEM_NAME = \"van_der_pol\"\n",
    "DATASET_NAME = \"vdp\"  # Simple clean name\n",
    "LORA_RANK = 8\n",
    "MAX_SEQ_LENGTH = 1024\n",
    "\n",
    "print(f\"üéØ Training system: {SYSTEM_NAME}\")\n",
    "print(f\"üìä Dataset: {DATASET_NAME}\")\n",
    "print(f\"üîß LoRA rank: {LORA_RANK}\")\n",
    "print(f\"üìè Max sequence length: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available datasets\n",
    "print(\"üìÇ Available datasets:\")\n",
    "datasets = list_available_datasets(\"../datasets\")\n",
    "if datasets:\n",
    "    for dataset in datasets:\n",
    "        print(f\"   ‚Ä¢ {dataset}\")\n",
    "else:\n",
    "    print(\"   No datasets found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VDP dataset (run this cell if you don't have the dataset)\n",
    "GENERATE_NEW_DATA = False  # Set to True to generate new data\n",
    "\n",
    "if GENERATE_NEW_DATA:\n",
    "    print(\"üîÑ Generating new Van der Pol dataset...\")\n",
    "    \n",
    "    generator = UniversalDataGenerator(\n",
    "        systems=[SYSTEM_NAME],\n",
    "        dt=ALL_CONFIG[\"system\"][\"dt\"],\n",
    "        steps=ALL_CONFIG[\"system\"][\"steps\"],\n",
    "        reasoning_start=ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        reasoning_end=ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        solution_start=ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        solution_end=ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    # Generate 2000 samples (1800 train + 200 eval)\n",
    "    data = generator.generate_single_system_dataset(SYSTEM_NAME, 2000)\n",
    "    train_data, eval_data = generator.split_dataset(data, 0.9)\n",
    "    \n",
    "    # Save dataset\n",
    "    import pickle\n",
    "    os.makedirs(\"../datasets\", exist_ok=True)\n",
    "    \n",
    "    with open(f\"../datasets/{DATASET_NAME}_train.pkl\", 'wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    with open(f\"../datasets/{DATASET_NAME}_eval.pkl\", 'wb') as f:\n",
    "        pickle.dump(eval_data, f)\n",
    "    \n",
    "    print(f\"‚úÖ Generated and saved dataset: {DATASET_NAME}\")\n",
    "    print(f\"   üìà Train samples: {len(train_data)}\")\n",
    "    print(f\"   üìä Eval samples: {len(eval_data)}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping data generation (set GENERATE_NEW_DATA=True to generate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing dataset\n",
    "try:\n",
    "    train_data, eval_data, dataset_info = load_train_eval_datasets(\n",
    "        DATASET_NAME, \"../datasets\", SYSTEM_NAME\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded dataset: {DATASET_NAME}\")\n",
    "    print(f\"   üìà Train samples: {len(train_data)}\")\n",
    "    print(f\"   üìä Eval samples: {len(eval_data)}\")\n",
    "    print(f\"   ‚ÑπÔ∏è  Dataset info: {dataset_info.get('config', {})}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load dataset: {e}\")\n",
    "    print(\"üí° Set GENERATE_NEW_DATA=True in the cell above to generate the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU and model manager\n",
    "print(\"üéØ Setting up GPU and model...\")\n",
    "\n",
    "# Auto-select best GPU\n",
    "gpu_config = auto_gpu_config()\n",
    "print(f\"üñ•Ô∏è  Selected GPU: {gpu_config['gpu_id']}\")\n",
    "\n",
    "# Create model manager\n",
    "manager = UniversalModelManager(ALL_CONFIG[\"model\"][\"base_model_name\"])\n",
    "\n",
    "# Setup model\n",
    "model, tokenizer = manager.setup_model(\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    lora_rank=LORA_RANK,\n",
    "    gpu_id=gpu_config['gpu_id'],\n",
    "    auto_select_gpu=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup chat template for single system\n",
    "setup_universal_chat_template(\n",
    "    manager, [SYSTEM_NAME],\n",
    "    ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "    ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "    ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "    ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Chat template configured for Van der Pol Oscillator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SFT Training (Optional)\n",
    "\n",
    "Run this section to train only the SFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFT Training\n",
    "RUN_SFT_ONLY = False  # Set to True to run SFT training only\n",
    "\n",
    "if RUN_SFT_ONLY:\n",
    "    print(\"üöÄ Starting SFT Training...\")\n",
    "    \n",
    "    # Update SFT config\n",
    "    sft_config = ALL_CONFIG[\"sft\"].copy()\n",
    "    sft_config[\"output_dir\"] = f\"../temp_training/{SYSTEM_NAME}/sft\"\n",
    "    \n",
    "    # Train SFT\n",
    "    sft_result = train_sft_model(\n",
    "        manager, train_data, eval_data, sft_config\n",
    "    )\n",
    "    \n",
    "    # Save SFT model\n",
    "    sft_save_path = save_sft_model(\n",
    "        manager, [SYSTEM_NAME], sft_result[\"metrics\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ SFT model saved to: {sft_save_path}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping SFT-only training (set RUN_SFT_ONLY=True to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SFT + GRPO Training (Combined)\n",
    "\n",
    "Run this section to train both SFT and GRPO models in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined SFT + GRPO Training\n",
    "RUN_COMBINED_TRAINING = True  # Set to True to run full training pipeline\n",
    "\n",
    "if RUN_COMBINED_TRAINING:\n",
    "    print(\"üöÄ Starting Combined SFT + GRPO Training...\")\n",
    "    \n",
    "    # === SFT Phase ===\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìö SFT TRAINING PHASE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sft_config = ALL_CONFIG[\"sft\"].copy()\n",
    "    sft_config[\"output_dir\"] = f\"../temp_training/{SYSTEM_NAME}/sft\"\n",
    "    \n",
    "    sft_result = train_sft_model(\n",
    "        manager, train_data, eval_data, sft_config\n",
    "    )\n",
    "    \n",
    "    sft_save_path = save_sft_model(\n",
    "        manager, [SYSTEM_NAME], sft_result[\"metrics\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ SFT model saved to: {sft_save_path}\")\n",
    "    \n",
    "    # === GRPO Phase ===\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéÆ GRPO TRAINING PHASE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    grpo_config = ALL_CONFIG[\"grpo\"].copy()\n",
    "    grpo_config[\"output_dir\"] = f\"../temp_training/{SYSTEM_NAME}/grpo\"\n",
    "    \n",
    "    grpo_result = train_grpo_model(\n",
    "        manager, train_data, eval_data, grpo_config,\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"reasoning_end\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_start\"],\n",
    "        ALL_CONFIG[\"system\"][\"solution_end\"]\n",
    "    )\n",
    "    \n",
    "    grpo_save_path = save_grpo_model(\n",
    "        manager, [SYSTEM_NAME], grpo_result[\"metrics\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GRPO model saved to: {grpo_save_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéâ TRAINING COMPLETED\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üìç SFT model: {sft_save_path}\")\n",
    "    print(f\"üìç GRPO model: {grpo_save_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping combined training (set RUN_COMBINED_TRAINING=True to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Evaluate your trained models on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "RUN_EVALUATION = True  # Set to True to run evaluation\n",
    "EVALUATE_SFT = True   # Set to True to evaluate SFT model\n",
    "EVALUATE_GRPO = True  # Set to True to evaluate GRPO model\n",
    "\n",
    "if RUN_EVALUATION:\n",
    "    print(\"üìä Starting Model Evaluation...\")\n",
    "    \n",
    "    # Load models for evaluation\n",
    "    eval_manager = UniversalModelManager()\n",
    "    \n",
    "    if EVALUATE_SFT:\n",
    "        print(\"\\nüîç Evaluating SFT Model...\")\n",
    "        try:\n",
    "            sft_model, sft_tokenizer, sft_lora, sft_metadata = eval_manager.load_single_system_model(\n",
    "                SYSTEM_NAME, model_type=\"sft\"\n",
    "            )\n",
    "            \n",
    "            # Generate test cases\n",
    "            system = get_system(SYSTEM_NAME)()\n",
    "            test_cases = []\n",
    "            for _ in range(10):  # 10 test cases\n",
    "                initial_state = system.generate_random_initial_state()\n",
    "                test_cases.append(tuple(initial_state))\n",
    "            \n",
    "            # Run inference\n",
    "            from vllm import SamplingParams\n",
    "            sampling_params = SamplingParams(\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                max_tokens=1024\n",
    "            )\n",
    "            \n",
    "            sft_results = run_batch_inference(\n",
    "                sft_model, sft_tokenizer, SYSTEM_NAME, test_cases,\n",
    "                lora_request=sft_lora,\n",
    "                sampling_params=sampling_params\n",
    "            )\n",
    "            \n",
    "            # Compute metrics\n",
    "            sft_metrics = compute_batch_metrics(sft_results)\n",
    "            \n",
    "            print(f\"‚úÖ SFT Evaluation Results:\")\n",
    "            print(f\"   Success rate: {sft_metrics['success_rate']:.2%}\")\n",
    "            print(f\"   Mean performance: {sft_metrics['mean_performance_score']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå SFT evaluation failed: {e}\")\n",
    "    \n",
    "    if EVALUATE_GRPO:\n",
    "        print(\"\\nüîç Evaluating GRPO Model...\")\n",
    "        try:\n",
    "            grpo_model, grpo_tokenizer, grpo_lora, grpo_metadata = eval_manager.load_single_system_model(\n",
    "                SYSTEM_NAME, model_type=\"grpo\"\n",
    "            )\n",
    "            \n",
    "            # Run inference\n",
    "            grpo_results = run_batch_inference(\n",
    "                grpo_model, grpo_tokenizer, SYSTEM_NAME, test_cases,\n",
    "                lora_request=grpo_lora,\n",
    "                sampling_params=sampling_params\n",
    "            )\n",
    "            \n",
    "            # Compute metrics\n",
    "            grpo_metrics = compute_batch_metrics(grpo_results)\n",
    "            \n",
    "            print(f\"‚úÖ GRPO Evaluation Results:\")\n",
    "            print(f\"   Success rate: {grpo_metrics['success_rate']:.2%}\")\n",
    "            print(f\"   Mean performance: {grpo_metrics['mean_performance_score']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå GRPO evaluation failed: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping evaluation (set RUN_EVALUATION=True to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results if evaluation was run\n",
    "if RUN_EVALUATION and EVALUATE_GRPO and 'grpo_results' in locals():\n",
    "    print(\"üìà Generating visualizations...\")\n",
    "    \n",
    "    # Plot trajectory comparison\n",
    "    fig1 = plot_comparison(grpo_results)\n",
    "    if fig1:\n",
    "        plt.figure(fig1.number)\n",
    "        plt.suptitle(f\"Van der Pol GRPO Model Results\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot metrics comparison\n",
    "    fig2 = plot_metrics_comparison(grpo_results)\n",
    "    if fig2:\n",
    "        plt.figure(fig2.number)\n",
    "        plt.suptitle(f\"Van der Pol Performance Metrics\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    print(\"‚úÖ Visualizations complete!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  No results to visualize (run evaluation first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook provides a complete workflow for training and evaluating Van der Pol oscillator control models:\n",
    "\n",
    "- **Data Generation**: Create clean VDP dataset (1800 train + 200 eval)\n",
    "- **SFT Training**: Supervised fine-tuning for basic control knowledge\n",
    "- **GRPO Training**: Reinforcement learning for optimal control\n",
    "- **Evaluation**: Test model performance on unseen data\n",
    "- **Visualization**: Plot trajectories and performance metrics\n",
    "\n",
    "**Model Outputs:**\n",
    "- SFT model: `models/single_system/van_der_pol/sft/latest/`\n",
    "- GRPO model: `models/single_system/van_der_pol/grpo/latest/`\n",
    "\n",
    "**Next Steps:**\n",
    "- Use the DI training notebook for Double Integrator\n",
    "- Use the universal training notebook for multi-system models\n",
    "- Load trained models in other notebooks for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}