# Model Analyzer

You are tasked with conducting deep analysis and comparison of trained models in the Universal Control LLM Framework.

## Instructions

1. **Use the model-analyzer agent** for comprehensive model evaluation
2. **Performance Analysis**:
   - Compare specialist vs universal models
   - Analyze performance across different systems and configurations
   - Statistical significance testing with confidence intervals
   - Performance ranking with detailed metrics

3. **Model Behavior Analysis**:
   - Training dynamics and convergence patterns
   - Hyperparameter impact assessment
   - Failure case analysis and categorization
   - Robustness and generalization evaluation

4. **Comparative Studies**:
   - Multi-model comparison with statistical rigor
   - Specialist vs universal model trade-offs
   - Training strategy effectiveness analysis
   - Resource efficiency vs performance analysis

## Usage Examples

- `/analyze-models` - Run comprehensive model analysis and comparison
- Can focus on specific model types, systems, or comparison aspects
- Provides detailed statistical analysis with practical recommendations
- Generates professional analysis reports with visualizations

## Agent Integration

This command automatically invokes the `model-analyzer` agent with specialized knowledge of:
- Statistical analysis and hypothesis testing
- LLM-based control system evaluation metrics
- Performance benchmarking and ranking methodologies
- Training dynamics analysis and interpretation
- Professional report generation with actionable insights

The agent provides rigorous analysis to identify the best models and understand their characteristics, enabling data-driven decisions for model selection and improvement.